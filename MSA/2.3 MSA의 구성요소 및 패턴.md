# MSA 구성 요소 및 패턴

- MSA 역시 검증된 아키텍쳐 스타일, 패턴이 존재한다.  
  개발자의 입장에서 마이크로서비스 시스템을 구현하기 위해 밟아야할 단계들을 순서대로 살펴보자.

- 우선은 `인프라가 구축`되어야 하고, 그 위에 `미들웨어`가 올라가고, 미들웨어 위에서 `애플리케이션이 동작`해야 한다.  
  따라서 `인프라`, 미들웨어 영역을 대신하고 있는 `플랫폼`, 그리고 `애플리케이션` 순으로 살펴보자.

- 먼저 클라우드 인프라 패턴이라고도 부를 수 있는 클라우드 인프라 영역의 구성요소를 살펴보자.

<table>
    <tr>
        <td>패턴 유형</td>
        <td>설명</td>
    </tr>
    <tr>
        <td>인프라 구성요소</td>
        <td>마이크로서비스를 지탱하는 하부구조 인프라를 구축하는 데 필요한 구성요소</td>
    </tr>
    <tr>
        <td>플랫폼 패턴</td>
        <td>인프라 위에서 마이크로서비스의 운영과 관리를 지원하는 플랫폼 차원의 패턴</td>
    </tr>
    <tr>
        <td>애플리케이션 패턴</td>
        <td>마이크로서비스 애플리케이션을 구성하는 데 필요한 패턴</td>
    </tr>
</table>

<hr/>

<h2>1. 인프라 구성요소</h2>

- IT에서 `인프라`라는 단어의 의미는 Enterprise IT 환경을 운영하고 관리하는 데 필요한 근간이 되는 하드웨어,  
  소프트웨어, 네트워킹 구성요소, 운영체제, 데이터 스토리지 등을 모두 포괄한다.  
  클라우드 환경에서는 이러한 인프라 구성요소들이 모두 가상화되어 제공된다.

<h3>온프레미스 vs 클라우드 환경</h3>

- AWS, GCP, Azure 등의 클라우드 서비스는 시스템의 자원 구성, 할당, 관리, 모니터링 등을 모두 제공하여  
  일련의 설정 작업들을 몇 번의 클릭만으로 처리할 수 있게 해준다.

- 이러한 환경에서 Architect가 해야하는 일은 가장 먼저 **맨 하부의 시스템의 기반이 되는 인프라 구축** 이다.  
  물론 이 과정에서 온프레미스 환경을 선택해도 된다. 하지만 가상화 장치 없이 온프레미스 환경의 장비들로 마이크로서비스  
  애플리케이션을 구동한다면 각 마이크로서비스마다 베어 메탈 장비를 구축해야 하고, 이는 당연히 인프라의 유연한  
  확장/축소를 기대하기 힘든 결과를 낼 것이다.

- 만약 가상 인프라 환경을 사용하기로 결정했다면, 그다음으로 가장 먼저 고려할 사항은 **VM 제품과 컨테이너 기반 제품 중 하나를 선택**  
  하는 것이다. 이 둘의 차이점을 알아보자.

<h3>VM, Container</h3>

- 우선, VM은 하이퍼바이저(Hypervisor)라는 소프트웨어를 이용해 하나의 시스템에서 여러 개의 OS를 사용하는 기술이다.  
  반면에 컨테이너는 하이퍼바이저 없이 컨테이너 엔진을 사용해 가상의 격리된 공간을 생성한다.

- 이 둘의 차이점은 Guest OS의 유무로 판단할 수 있는데, VM의 경우 Guest OS는 Host OS와 라이브러리(애플리케이션) 사이에  
  Hypervisor와 함께 위치하지만, 컨테이너의 경우에는 Docker Engine만이 Host OS와 라이브러리 사이에 위치한다.

- Guest OS를 사용하는 VM에는 운영체제 패치 설치나 관련 라이브러리 설치와 같은 오버헤드가 지속적으로 발생한다.  
  따라서 **마이크로서비스 같은 작은 서비스를 패키징하고 배포하기에는 컨테이너가 더 적합** 하다.

- 가장 대표적인 컨테이너 기수로는 필요한 라이브러리나 실행 파일을 여러 개의 Layer로 된 Image로 추가하거나 변경할 수 있는  
  Docker가 있다.

- Docker Container는 아래와 같은 계층으로 구성된다.

  - Image Layer 3 (Application)
  - Image Layer 2 (Runtime)
  - Image Layer 1 (OS)
  - Base Image (Base RHEL)

- Docker Container의 이점은 아래와 같다.

  - 이식성: 어떠한 호스트 커널이나 플랫폼 버전에 관계없이 Docker만 실행할 수 있으면 사용 가능하며 동일하게 동작된다.
  - 신속성: 크기가 작고 가볍기에 빠르게 배포가 가능하며, 문제 발생 시 수정할 필요 없이 새로 기동하면 된다.
  - 재사용성: 동일한 환경을 재사용해서 쉽게 설정 가능하기에 개발, 테스트, 스테이징, 프로덕트 환경을  
    동일한 환경으로 구축하기가 쉽다.

- 결론적으로 마이크로서비스와 같이 가변적이고 유연한 속성을 갖추기 위해서는 Container 기반의 아키텍쳐가 더욱 어울린다.

<h3>Container Orchestration</h3>

- 컨테이너 기술을 사용할 때에는 컨테이너를 관리하기 위한 기술 또한 필요하다.  
  컨테이너가 많아지면 그에 따라 컨테이너의 자동 배치 및 복제, 장애 복구, 확장 및 축소, 컨테이너 간의 통신,  
  로드 밸런싱 등의 컨테이너 관리를 위한 기능이 필요해진다.

- 이러한 기술을 Container Orchestration이라 하며, 이를 위한 도구로는 Docker Swarm, Apache Mesos 등이 있다.  
  최근에는 Google이 공개한 Kubernetes가 큰 인기를 끌고 있다.

- Kubernetes 대시보드를 보면 컨테이너 배포의 기본 단위에 해당하는 Pod, Deployment, Replica Set 등의  
  정보를 확인하고 설정할 수 있다. Kubernetes는 아래와 같은 주요 기능들을 제공한다.

  - Automatic Binpacking: 각 컨테이너가 필요로 하는 CPU와 메모리를 K8s에 요청하면 컨테이너를 노드에 맞춰 자동 배치한다.
  - Self-healing: 컨테이너에 대해 health check를 수행하여 실패한 경우 자동으로 교체하고 re-scheduling 한다.
  - Horizontal Scaling: 일정 CPU 및 메모리 사용량을 초과하면 자동으로 확장한다.

- 또한 Kubernetes는 일부 마이크로서비스 운영/관리 패턴을 자체적으로 내장하고 있기도 하다.

<hr/>

<h2>마이크로서비스 운영과 관리를 위한 플랫폼 패턴</h2>

- 애플리케이션이 실제로 구동되는 인프라 환경을 결정했다면 그 다음으로 선택한 인프라 환경 위에서  
  애플리케이션을 운영하고 관리하는 환경을 구성하는 방법을 생각해야 한다.  
  특히 **애플리케이션을 빌드하고 인프라에 배포할 수 있는 환경** 이 중요하다.  
  왜냐하면 마이크로서비스 환경을 구성하는 수많은 마이크로서비스들을 하나하나 빌드하고 배포한다면  
  굉장히 비효율적이고 큰 혼란을 가져올 것이기 때문이다.

 <h3>개발 지원 환경: DevOps 인프라 구성</h3>

- 필요한 요소는 마이크로서비스를 빌드하고 테스트한 뒤 배포할 수 있게 도와주는 개발환경인 DevOps 환경이다.  
  DevOps는 개발과 운영이 분리되지 않은 개발 및 운영을 병행할 수 있는 조직 또는 그 문화를 일컫는데,  
  여기서는 협의의 의미로 개발과 운영을 병행 가능하게끔 높은 품질로 소프트웨어를 빠르게 개발하도록 지원하는  
  빌드, 테스트, 배포를 위한 자동화 환경을 말한다.

- 그럼 자동화 환경이 있기 전의 수동 배포 절차를 살펴보자.

  - (1) 개발자가 개발 환경에서 애플리케이션을 완성하고, 컴파일하고 수동 테스트 후 발생한 오류를 수정한 뒤 스테이징 환경에 배포한다.
  - (2) 운영 환경 배포 전에 스테이징 환경에서 다시 테스트한다. 그러다 예상치 못한 오류를 발견하면 다시 첫 환경인 개발 환경으로 돌아가  
    오류를 수정한 뒤 다시 스테이징 환경에서 테스트를 수행한다.
  - (3) 위 과정에 무사히 끝나면 배포 승인을 받고 배포 담당자가 애플리케이션을 운영 환경에 배포한다.

- 위와 같은 수동 빌드/배포 과정에는 정말 많은 시간이 소모되며, 대부분의 경우에는 시스템 사용률이 낮은 새벽 시간대에 시스템을  
  장시간 멈추고 배포 작업을 진행하는 경우가 많다. 당연히 이러한 환경에는 비즈니스 민첩성이 높을 수가 없다.  
  특히 여러 개의 마이크로서비스를 배포해야 하는 환경에서는 배포가 잦을 수 밖에 없기에 자동화가 절실하다.

- 마이크로서비스는 당연히 각 마이크로서비스마다 Repository를 다르게 가지기에 각 서비스마다 각각의  
  CI/CD 파이프라인이 구축되어 자동화가 진행되어야 한다.

<h3>마이크로서비스 생태계와 운영 관리 요소의 탄생</h3>

- Netflix가 스트리밍 산업을 한지 얼마 되지 않아 스트리밍 데이터베이스 스토리지가 손실되는 대규모 서비스 장애를 겪었다.  
  이를 계기로 Netflix는 한 덩어리의 모노리스 시스템에서 마이크로서비스 기반의 시스템으로 전환하는 작업을 시작한다.  
  이때 선택한 것은 AWS EC2 이다.

- 그러나 클라우드 기반에서 마이크로서비스로 전환하는 것은 쉽지 않았다. 우선 애플리케이션이 한 덩어리일 때 발생하지 않았던  
  여러 문제점들이 불거졌다. 전체 서비스를 여러 개의 서비스로 분산 구성했을 때 한 서비스에서 발생한 장애가 다른 서비스로  
  전파된다거나 여러 서비스에 분산된 로그를 관리해야하는 불편함, 서비스가 하나로 동작하지 않아 시스템의 일부 기능이  
  동작하지 않아도 그것을 알아채지 못하고 장애가 방치되는 문제들이 발생했다.

- 이러한 문제들을 해결하기 위해 Netflix는 다양한 서비스와 도구를 개발하게 되었으며, 이를 오픈소스로 공개했는데,  
  이것이 바로 Netflix OSS 이다. Netflix OSS에는 여러 마이크로서비스 간의 Routing과 Load Balancing을 위한  
  Zuul과 Ribbon, 모니터링을 위한 Hystrix, 서비스 등록을 위한 Eureka 등이 포함되어 있다.

<h3>마이크로서비스 관리/운영 패턴</h3>

- 마이크로서비스 구축 시 발생하는 문제는 주로 시스템을 여러 개의 서비스로 구성하기 때문에 발생하는 문제이다.  
  Netflix가 이 문제를 해결하는 데 크게 기여했는데, Netflix OSS는 Netflix가 마이크로서비스를 개발하고  
  운영하면서 생긴 노하우를 다른 사람들도 쉽게 사용할 수 있도록 공유한 오픈소스이다. 이는 마이크로서비스 생태계에  
  크게 도움이 되었고, 특히 마이크로서비스 관리와 운영을 지원하는 전형적인 마이크로서비스 애플리케이션 패턴으로  
  자리잡았다. 예를 들어 API Gateway, Service Discovery, Monitoring, Tracing 등이 다수의  
  마이크로서비스를 관리 및 운영하기 위한 플랫폼 패턴으로서 Netflix에서 소스 코드를 공개하고 나서 패턴으로  
  정착되고 나중에 이러한 패턴을 적용한 다른 여러 도구들과 오픈소스들이 생겨나는 밑거름으로 작용했다.

- 또한 Netflix OSS를 더 쉽게 쓸 수 있도록 Spring에서는 기존의 Spring Boot Framework에서 잘 돌아갈 수  
  있도록 Netflix OSS Module을 Spring Framework로 감싸서 Spring Cloud라는 이름으로 발표했다.  
  이를 통해 Spring Boot와 Spring Cloud는 마이크로서비스를 개발하기 위한 가장 대중적인 프레임워크로  
  자리매김했다. Spring Boot + Spring Cloud의 조합을 사용하면 마이크로서비스 애플리케이션의 운영 환경을  
  쉽게 구축할 수 있다.

<h3>Spring Cloud: Spring Boot + Netflix OSS</h3>

- Spring Cloud를 이용한 마이크로서비스 구조에 대해 살펴보자.

1. 모든 마이크로서비스는 인프라에 종속되지 않도록 데이터베이스, 파일 등에 저장된 환경 설정 정보를  
   형상 관리 시스템에 연계된 Configuration Service에서 가져와 설정 정보를 주입한 후 클라우드  
   인프라의 개별 인스턴스로 로딩된다.

2. 로딩과 동시에 Service Registry에 자신의 서비스명과 클라우드 인프라로부터 할당받은 물리적 주소를  
   매핑해서 등록한다.

3. 클라이언트가 API Gateway를 통해 마이크로서비스에 접근하고, 이때 API Gateway는 적절한 Routing  
   및 부하 관리를 위한 Load Balancing을 수행한다.

4. 또한 API Gateway에서 클라이언트가 마이크로서비스에 접근하기 위한 주소를 알기 위해 Service Registry를  
   검색을 통해 서비스의 위치를 가져온다.

5. 동시에 API Gateway는 클라이언트가 각 서비스에 접근할 수 있는 권한이 있는지를 판단하기 위해  
   Authentication Service와 연계하여 인증/인가 처리를 수행한다.

6. 이러한 모든 마이크로서비스 간의 호출 흐름은 Monitoring Service와 Tracing Service에 의해 모니터링되고  
   추적된다.

- 위의 흐름이 MSA의 주요 아키텍쳐 패턴이기에 AWS, Azure, GCP 등에서도 이를 자체 기능 또는 과금되는 별도 서비스로  
  제공한다. 이어서 널리 사용되는 MSA 패턴 중심으로 하나씩 자세히 살펴보자.

<h3>Service Registry, Service Discovery 패턴</h3>

- Frontend 클라이언트가 여러 개의 Backend 마이크로서비스를 어떻게 호출해야 할까?  
  또한 Scale-Out를 통해 인스턴스가 여러 개로 복제되었다면 어떻게 부하를 적절히 분산할 수 있을까?

- 위 질문들을 위한 패턴이 `Service Discovery Pattern`이다. 클라이언트가 여러 개의 마이크로서비스를  
  호출하기 위해서는 최적 경로를 찾아주는 Routing 기능과 적절한 부하 분산을 위한 Load Balancing 기능이  
  제공되어야 한다. Netflix OSS의 경우, Routing은 Zuul이, Load Balancing은 Ribbon이 담당한다.

- 라우터는 최적 경로를 탐색하기 위해 서비스 명칭에 해당하는 IP 주소를 알아야 한다.  
  그런데 이러한 라우팅 정보를 클라이언트가 가지고 있으면 클라우드 환경에서 동적으로 변경되는 Backend의  
  유동 IP 정보를 매번 전송받아 변경해야 한다. 따라서 제3의 공간에서 이런 정보를 관리하는 것이 좋다.

- 즉 Backend 마이크로서비스 서비스의 명칭과 유동적인 IP 정보를 매핑해서 보관할 저장소가 필요한 것이다.  
  Netflix OSS의 Eureka가 이 기능을 담당하고, 이러한 패턴을 `Service Registry Pattern`이라 한다.

- 우선 각 서비스 인스턴스가 로딩될 때 자신의 서비스명과 할당된 IP 주소를 Registry Service에 등록한다.  
  그런 다음, 클라이언트가 해당 서비스명을 호출할 때 Router가 Registry Service를 검색해 해당 서비스의  
  이름과 매핑된 IP 정보를 확인한 후 호출한다. 이 Registry Service는 모든 마이크로서비스 인스턴스의  
  주소를 알고 있는 서비스 매핑 저장소가 된다. 모든 마이크로서비스가 처음 기동할 때 자신의 위치 정보를  
  저장하고 서비스가 종료될 때 위치 정보가 삭제된다.

- Service Registry에는 업무 처리를 위한 마이크로서비스 뿐만 아니라 관리와 운영을 위한 기반 서비스의  
  주소도 함께 보관한다. 예를 들면 Configuration Service, Monitoring, Tracing Service도 모두  
  이름을 가지고 있기에 주소를 가지고 있어야 한다.

- 실제로 Spring Eureka로 구현된 Registry Service를 보면, 서비스명과 IP 주소 및 포트 정보가  
  매핑된 것을 확인할 수 있다. 다수의 인스턴스가 하나의 서비스명으로 등록 될 때 다수의 IP 주소와 포트 정보가  
  매핑되고, Router는 이 정보를 질의해서 Load Balancing도 할 수 있다.

<h3>서비스 단일 진입을 위한 API Gateway 패턴</h3>

- 여러 클라이언트가 여러 개의 서버 서비스를 각각 호출하게 된다면 매우 복잡한 호출 관계가 만들어질 것이다.  
  이러한 복잡성을 통제하기 위한 방법 중 하나가 API Gateway이다.

- API Gateway는 다양한 클라이언트가 다양한 서비스에 접근하게 할 수 있도록 단일 진입점을 만들어놓는다.  
  무조건 단일 진입점을 먼저 거치게 한다면, 다른 유형의 클라이언트에게 서로 다른 API 조합을 제공할 수도 있고,  
  각 서비스에 접근할 때 필요한 인증/인가 기능을 한 번에 처리할 수 있다. 또한 정상적으로 작동하던 서비스에  
  문제가 생겨 응답 지연이 발생하면 정상적인 다른 서비스로 요청 경로를 변경하는 기능을 구현할 수도 있다.

- 이러한 서비스 흐름 제어를 위한 서비스 라우팅 기능은 소프트웨어, 하드웨어 둘 다로 구현할 수 있는데,  
  소프트웨어로 구현할 경우 API Gateway가 Application Level의 Routing을 수행한다.  
  또한 여러 인스턴스로 부하를 분산하는 Load Balancing도 수행하고, Routing시 필터를 두어  
  Routing 전과 후에 각각 수행되는 선행, 후행처리 및 에러처리를 손쉽게 할 수 있다.

- 정리하자면, API Gateway는 다른 서비스들과 연계해서 아래와 같은 기능들을 제공한다.

  - Registry Service와 연계한 Dynamic Routing, Load Balancing
  - 보안: 권한 서비스와 연계한 인증/인가
  - Logging Service와 연계한 로깅
  - Metrics(에러율, 평균/최고 지연시간, 호출 빈도 등)
  - Tracing Service와 연계한 서비스 추적
  - Monitoring Service와 연계한 장애 격리

- 이러한 API Gateway Pattern은 Spring API Gateway Service로 간단한 어노테이션만으로  
 손쉽게 적용할 수 있다.
<hr/>

<h3>BFF 패턴</h3>

- 최근에는 PC 뿐만아니라 다양한 모바일 장치를 사용하기에 다양한 클라이언트를 고려해야 한다.  
  이처럼 다양한 클라이언트를 위해서는 특화된 처리를 위한 API들의 조합이나 처리가 필요하다.  
  이를 위한 해결 방법으로 BFF(Backend for Frontend) 패턴이 있다.

- BFF 패턴은 API Gateway와 같은 진입점을 하나로 두지 않고, Frontend의 유형에 따라  
 각각 두는 패턴이다. 웹을 위한 API Gateway, 모바일을 위한 API Gateway 등과 같이  
 클라이언트의 종류에 따라 최적화된 처리를 수행할 수 있게 구성할 수 있다.  
 이로써 모바일을 위한 API만 선택해서 제공하거나 웹을 위한 API만 적절하게 제공할 수 있다.  
 또한 각 Frontend에 대한 처리만 수행하는 BFF를 가장 앞에 놓고, 그 이후에 통합적인  
 API Gateway를 두어 공통적인 인증/인가, 로깅 등의 처리를 하는 구조로 구성할 수도 있다.
<hr/>

<h3>외부 구성 저장소 패턴</h3>

- 마이크로서비스를 구현하면, 재배포를 할 때 데이터베이스 설정 정보 등 애플리케이션의 수행에 필요한  
  설정값들이 변경될 수 있다. 또한 설정 정보 자체가 바뀌면 만약 여러 마이크로서비스가 동일한 구성 정보를  
  사용하는 경우에도 일일이 변경하기가 어렵고, 실수가 발생할 수도 있다.  
  따라서 마이크로서비스가 사용하는 자원의 설정 정보를 쉽고 일관되게 변경 가능하도록 관리할  
  필요가 있다,

- 이를 위한 방법이 외부 저장소 패턴인데, 외부 저장소는 각 마이크로서비스의 외부 환경 설정 정보를  
  공동으로 저장하고 가지고 있는 백업 저장소이다.

- 클라우드에서 운영되는 애플리케이션은 특정한 배포 환경에 종속된 정보를 코드에 두면 안된다.  
  왜냐하면 이런 정보들을 코드에 두면 배포 환경이 변경됐을 때 애플리케이션 또한 변경해야하기 때문이다.  
  이렇게 분리해야할 정보로는 DB 연결 정보, 배포 시 변경해야 할 호스트명, 백엔드 서비스의 연결을 위한  
  리소스 정보 등이 있다.

- 예를 들어, Spring Cloud Config을 사용하면 이러한 환경 정보를 코드에서 분리하고  
  Configuration Service를 통해 Runtime시에 주입되게 할 수 있다.  
  환경 정보는 Git과 같은 repository에 보관하고 Configuration Service는  
  해당 서비스가 특정 환경에 배포될 때 적절한 환경 정보를 가져와 해당 서비스에 주입한다.

- K8s는 이러한 외부 구성 저장소 패턴을 ConfigMap으로 제공한다.
<hr/>

<h3>인증/인가 패턴</h3>

- 여러 마이크로서비스 각각이 모두 인증/인가를 중복으로 구현한다면 매우 비효율적이다.  
  따라서 마이크로서비스가 인증/인가를 처리하기 위해 사용하는 패턴을 살펴보자.

<h4>중앙 집중식 세션 관리</h4>

- 기존 모노리스 방식에서 가장 많이 사용했던 방식은 서버의 세션에 사용자의 로그인 정보 및 권한 정보를  
  저장하고, 이를 통해 애플리케이션의 인증/인가를 판단하는 것이다. 그렇지만 마이크로서비스는 사용량에 따라  
  수평 확장이 될 수도 있고 Load Balancing처리가 되기에 세션 데이터가 유실될 수도 있다.  
  따라서 마이크로서비스는 각자의 서비스에 세션을 저장하지 않고 공유 저장소에 세션을 저장하고, 모든 서비스가  
  동일한 사용자 데이터를 얻게 한다. 세션 저장소로는 보통 Redis, MemCached를 사용한다.

<h4>클라이언트 토큰</h4>

- 익히 알고 있는 JWT 인증 방식이다. 세션은 중앙 서버에 저장되며 토큰은 클라이언트 측에서 보관한다.

<h4>API Gateway를 사용한 클라이언트 토큰</h4>

- 사용자 인증 프로세스는 토큰 인증 프로세스와 유사하다. 차이점은 API Gateway가 외부 요청의 입구로  
   추가된다는 것이다. 또한 인증/인가를 처리하기 위한 별도의 전담 서비스(Auth Service)를 만들어서  
   다른 서비스의 인증/인가 처리를 위임하도록 한다. 이렇게 Auth Service를 API Gateway와  
   연동해서 이용하면 각 리소스 서비스가 자체적으로 인증/인가를 처리하지 않고 업무 처리에 집중할 수 있다.  
   순서는 아래와 같다.

  1. 클라이언트가 리소스 서비스에 접근을 요청하면 API Gateway는 인증 서비스에게 전달한다.
  2. 인증 서비스는 해당 요청이 인증된 사용자가 보낸 것인지를 검증하는 인증 단계와, 해당 리소스에 대한 접근  
     권한이 있는지를 파악하는 인가 단계를 모두 진행하고, 모두 확인하고 나면 리소스 접근을 허용하기 위한  
     AccessToken을 지급한다.
  3. 클라이언트는 AccessToken과 함께 다시 접근을 요청한다.
  4. 각 리소스는 이러한 요청이 AccessToken을 포함하고 있는지를 판단해서 리소스에 대한 접근을 허용한다.
  <hr/>

<h3>장애 및 실패 처리를 위한 Circuit Breaker 패턴</h3>

- 여러 개의 서비스로 구성된 시스템에서는 한 서비스에 장애가 생겼을 때 다른 서비스가 영향을 받을 수 있다.  
  이때, 장애가 발생한 서비스를 격리해서 유연하게 처리할 수 있는 방법이 필요한데, 이를 위한 한 가지 방법이  
  서킷 브레이커 패턴이다.

- 서비스의 수가 많아지면 분명한 장점도 있지만 단점 또한 분명히 존재한다. 예를 들면 사용자가 접하는 전체 시스템은  
  정상적인데 특정 기능을 사용하려 하면 즉각 에러가 발생하지도 않고 한참 동안 대기하는 상황이 발생할 수도 있다.  
  사용자 입장에서는 이같은 상황이 장애인지 판단도 되지 않으며 단순히 시스템이 느려졌다고 판단할 수도 있다.  
  이러한 상황은 정상적인 서비스가 장애가 발생한 서비스에 의존해서 서비스를 제공할 때 문제가 발생하는 상황으로서  
  장애가 다른 서비스로 *전이*된 상태이다. 이러한 일을 막기 위해 특정 서비스에 문제가 생겼을 때 자연스럽게  
  다른 정상적인 서비스로 요청 흐름이 변경되도록 해야 한다. 이렇게 하기 위해서는 서비스 상태를 실시간으로 관리해서  
  시각화하고 모니터링할 수 있어야 하고, 특정 서비스에서 장애가 감지되면 장애가 다른 서비스로 전이되지 않게 하는  
  방법이 반드시 필요하다.

- 간단한 흐름을 살펴보자. Service A가 Service B를 호출해서 자신의 서비스를 제공하는데, Service B에서  
 장애가 발생하면 동기 요청(Request)의 특성상 Service A는 계속해서 Service B의 응답을 기다리게 된다.  
 이 경우, 사용자 입장에서는 Service A도 장애가 발생한 것처럼 느껴진다. 서킷 브레이커 패턴은 이와 같은  
 경우에 Service B의 호출에 대한 연속 실패 횟수가 임계값을 초과하면 이후에 Service B를 호출하려는 모든  
 시도를 즉각 실패처리 하게 만든다. 그리고 Fallback 메소드를 지정해 두면 장애가 발생했을 때 Fallback  
 메소드가 자연스럽게 격리를 진행하게 된다. 그럼 사용자는 특정 서비스에 장애가 발생했는지 눈치채지 못하고  
 시간이 흘러 장애가 복구되었을 때 다시 호출을 정상화하면 된다.
<hr/>

<h3>Monitoring, Tracing Pattern</h3>

- 위에서 Circuit Breaker Pattern이 잘 작동하게 하기위해 기본적으로 필요한 것은 *서비스 장애의 감지*이다.  
  이를 감지하려면 각 마이크로서비스의 장애를 실시간으로 감지해야 하고, 서비스 간의 호출이 어떤지 알아야 한다.  
  즉, 모니터링하고 추적하는 패턴이 필요하다. Spring Cloud에서는 Hystrix라는 라이브러리를 제공하고,  
  이 라이브러리가 배포된 서비스를 모니터링할 수 있는 Hystrix Dashboard를 제공함으로써 마이크로서비스의  
  요청을 실시간으로 모니터링할 수 있다.

- 다음으로 알아볼 것은 분산 추적 서비스이다. 모니터링과 함께 각 서비스 트랜잭션의 호출을 추적하면  
 마이크로서비스의 운영에 매우 유용하다. 트위터의 Zipkin과 같은 대시보드를 사용하면 분산된 서비스 간의  
 호출이나 지연 구간별 장애 포인트를 확인할 수 있다.
<hr/>
