# Amazon Redshift

- A fast, fully-managed, petabyte-scale data warehouse.
- Based on PostgreSQL 8.0.2, but contains a number of differences from PostgreSQL.

- A data warehouse is used to consolidate data from multiple sources to allow you to run business intelligent tools,  
  across your data, to help you identify actionable business information, which can then be used to direct and  
  drive your organization to make effective data-driven decisions to the benefit of your company.

- As a result, using a data warehouse is a very effective way to manage your reporting and data analysis at scale.  
  A data warehouse, by its very nature, needs to be able to store huge amounts of data and its data may be  
  subjected to different data operations such as data cleansing, which as an example, may identify, correct,  
  replace or remove incomplete records from a table or recordset.

- This can be expanded upon for the need to perform an extract, transform and load or an ETL job.  
  This is the common paradigm by which data from multiple systems is combined to a single database data store  
  or warehouse for legacy storage or analytics.

## ETL Overview

### Extraction

- Extraction is the process of retrieving data from one or more sources.  
  Either online, brick & mortar, legacy data, Salesforce data and many others.  
  After retrieving the data, ETL is to compute work that loads it into a staging area and prepares it for the next phase.

### Transformation

- Transformation is the process of mapping, reformatting, conforming, adding meaning and more to prepare  
  the data in a way that is more easily consumed. One example of this is the transformation and computation  
  where currency amounts are converted from US dollars to euros.

### Loading

- Loading involves successfully inserting the transform data into the target database data store,  
  or in this case, a data warehouse. All of this work is processed in what the business intelligent  
  developers call an ETL job.

---

## Components

### Amazon Redshift Cluster

- A cluster can be considered the main or core component of the Amazon Redshift service.  
  And in every cluster, it will run its own Redshift engine, which will contain at least one database.  
  As the name implies, a cluster is effectively a grouping of another component, and these being compute nodes.

- Each will contain at least one compute node. However, if the cluster is provisioned with more than one compute node,  
  then Amazon Redshift will add another component called a leader node.

- Compute nodes all contain their own quantity of CPU attached storage and memory.  
  And there are different nodes that offer different performances.

![picture 2](/images/AWS_SAA_REDSHIFT_1.png)

- The leader node of the cluster has the role of coordinating communication between your compute nodes  
  in your cluster and your external applications accessing your Redshift data warehouse.  
  So the leader node is essentially gateway into your cluster from your applications.  
  When external applications are querying the data in your warehouse, the leader node will create execution plans,  
  containing code to return the required results from the database.

- If the query from the external application references tables associated with the compute nodes,  
  then this code is then distributed to the compute nodes in the cluster to obtain the required data,  
  which is then sent back to the leader node. If the query does not reference tables stored on the compute nodes,  
  then the query will run on the leader node only.

![picture 3](/images/AWS_SAA_REDSHIFT_2.png)

- Each compute node itself is also split into slices, known as node slices.  
  A node slice is simply a partition of a compute node where the nodes memory and disk spaces split.  
  Each node slice then processes operations given by the leader node where parallel operations can then be  
  performed across all slices and all nodes at once for the same query.  
  As mentioned previously, compute nodes can have different capacities and these capacities determine  
  how many slices each compute node can be split into.

- When creating a table, it is possible to distribute rows of that table across different nodes slices  
  based upon how the distribution case is defined for the table.

---

## Connecting to Redshift

- Communication between your application and Redshift will use industry standard open database connectivity, ODBC.  
  And JDBC for PostgreSQL.

---

## Understanding Performance

- From a query perspective, Amazon Redshift has a number of features to return results quickly and effectively.

### Massively Parallel Processing(MPP)

- By associating rows from tables across different nodes slices and nodes, it allows the leader node to  
  generate execution plans, to distribute crews from external applications across multiple compute nodes at once,  
  allowing them to work together to generate the end result, which is an aggregated by the leader node.

### Columnar Data Storage

- This is used as a way of reducing the number of times the database has to perform disk I/O,  
  which helps to enhance query performance. Reducing the data retrievals from the disk means there is more memory  
  capacity to carry out in memory processing of the query results.

### Result caching

- Result caching helps to reduce the time it takes to carry out queries by caching some results of the queries  
  in the memory of the leader node in a cluster. As a result, when a query is submitted, the leader node will check  
  its own cache copy of the results and if a successful match is found, the cached results are used instead of  
  executing another query on your Redshift cluster.

---

## Monitoring

- Amazon Redshift also integrates with Amazon CloudWatch, allowing you to monitor the performance of your  
  physical resources, such as CPU utilization and throughput. In addition to this, Redshift also generates query  
  and load performance data that enables you to track overall database performance.  
  Any data relating to query and load performance is only accessible from within the Redshift console itself  
  and not Amazon CloudWatch.

---
