# 사용자 수에 따른 규모 확장성

## 단일 서버

- 이전에는 웹, 앺, 데이터베이스, 캐시 등을 모두 한 대의 서버에서 실행했다.

<hr/>

## 데이터베이스

- 사용자가 늘면 서버 하나로는 충분하지 않아, 여러 서버를 둬야 한다.  
  예를 들어 하나는 웹 또는 모바일 트래픽 처리 용도로, 다른 하나는 데이터베이스용이다.  
  이렇게 웹 계층과 데이터 계층으로 분리하면, 그 각각을 독립적으로 확장해나갈 수 있다.

### 어떤 데이터베이스를 사용할까?

#### RDBMS(Relational Database Management System)

- MySQL, Oracle, PostreSQL 등의 RDBMS는 자료를 테이블과 row, column으로 표현한다.  
  SQL을 사용해 여러 테이블에 있는 데이터를 그 관계에 따라 join해 합칠 수 있다.

#### NoSQL Database

- Cassandra, Amazon DynamoDB 등 NoSQL은 비정형 데이터베이스다.  
  NoSQL은 다시 네 부류로 나눌 수 있다.

  - Key-Value Store
  - Graph Store
  - Column Store
  - Document Store

- 아래와 같은 경우에는 NoSQL(비관계형) 데이터베이스가 바람직한 선택일 수 있다.

  - 매우 낮은 latency의 요구
  - 다루는 데이터가 비정형(unstructured)이라 관계형 데이터가 아닌 경우
  - 데이터(JSON, YAML, XML 등)를 직렬화하거나(serialize) 역직렬화(deserialize)할 수 있기만 하면 되는 경우
  - 아주 많은 양의 데이터를 저장할 필요가 있는 경우

<hr/>

## 수직적 규모 확장 VS 수평적 규모 확장

- **수직적 규모 확장(Vertical Scaling)** : Scale Up이라고도 불리며, 서버에 고사양 자원(더 좋은 CPU, 더 많은 RAM 등)을  
  추가하는 행위.

- **수평적 규모 확장(Horizontal Scaling)** : Scale Out이라고도 불리며, 더 많은 서버를 추가해 성능을 개선하는 행위.

- 서버로 유입되는 트래픽 양이 적을 때 => **수직적 확장**

- 수직적 확장의 단점

  - 한계가 명확하다. 한 대의 서버에 CPU나 메모리를 무한대로 증설할 방법이 없다.
  - 장애에 대한 자동복구(failover) 방안이나 다중화(redundancy) 방안을 제시하지 않는다.

- 따라서 대규모 애플리케이션을 지원하는 데는 **수평적 확장**이 적합하다.

### 로드 밸런서(Load Balancer)

- **Load Balancer** : 부하 분산 집합(Load Balancing Set)에 속한 웹 서버들에게 트래픽 부하를 고르게 분산하는 역할

### 데이터베이스 다중화

- 서버와 마찬가지로 데이터베이스 역시 장애의 자동복구, 다중화를 지원하도록 해야 한다.  
  이를 위한 한 가지 방법을 보자.

- 데이터베이스 서버가 주(master)와 부(slave) 관계로 구성되며, 데이터 원본은 master에, 사본은 slave에 저장한다.  
  Write Operation은 master에서만 지원한다. Slave 들은 master로부터 그 사본을 전달받으며, read operation만을  
  지원한다. 예를 들어 INSERT, UPDATE, DELETE문은 모두 master로 전달되어야 한다.

- 대부분의 애플리케이션은 read 연산의 비중이 write 연산보다 훨씬 높다. 따라서 통상 slave의 수가 master보다 많다.

- 데이터베이스 다중화의 장점

  - **더 나은 성능** : master-slave 다중화 모델에서 모든 데이터 변경은 master로만 전달되는 반면,  
    read는 slave들로 분산된다. 병렬로 처리할 수 있는 query수가 늘어나므로, 성능이 좋아진다.

  - **안정성(Reliablity)** : 데이터베이스 서버 가운데 일부가 파괴되어도 데이터는 보존될 수 있다.

  - **가용성(Availability)** : 데이터를 여러 지역에 복제해둠으로써 하나의 데이터베이스 서버에  
    장애가 발생하더라도, 다른 서버에 있는 데이터를 가져와 계속 서비스할 수 있다.

- 로드밸런서가 시스템 가용성을 높이는 것처럼, 데이터베이스 중 하나가 다운되는 상황을 살펴보자.

  - slave가 하나 뿐인데 다운되었다면, read 연산은 한시적으로 모두 master로 전달된다. 또한 즉시 새로운 slave가  
    장애 서버를 대체하게 된다. slave가 여러 대인 경우에 read 연산은 나머지 slave들로 분산될 것이며, 새로운  
    slave가 장애 서버를 대체할 것이다.

  - master가 다운된다면, 한 대의 slave만 있는 경우에는 해당 slave가 새로운 master가 되며, 일시적으로  
    모든 데이터베이스 연산이 새로운 master에서 수행된다. 그리고 새로운 slave가 추가된다.  
    production 환경에서 벌어지는 일은 이보다 더 복잡한데, slave에 보관된 데이터가 최신 상태가 아닐 수 있기 때문이다.  
    없는 데이터는 복구 스크립트(recovery script)를 돌려 추가해야 한다. mutli-masters나 circular-replication 방식을  
    도입하면 이런 상황에 대처하는 데는 도움될 수 있지만, 해당 구성은 훨씬 더 복잡하다.

<hr/>

## 캐시

- **캐시(cache)** : 값비싼 연산 결과 또는 자주 참조되는 데이터를 메모리 내에 두고, 뒤이은 요청이 보다 빠르게  
  처리될 수 있도록 해주는 저장소

- 애플리케이션의 성능은 데이터베이스를 얼마나 자주 호출하느냐에 따라 크게 좌우되는데, 캐시는 그런 문제를 완화할 수 있다.

### 캐시 계층

- 캐시 계층(Cache Tier)은 데이터가 잠시 보관되는 곳으로, 데이터베이스보다 훨씬 빠르다.  
  별도의 캐시 계층을 두면 성능 개선 뿐만 아니라 데이터베이스의 부하 감소도 가능하며, 캐시 계층의 규모를 독립적으로  
  확장시키는 것도 가능하다.

- 아래는 캐시 서버를 두는 방법 중 하나다.

  - (1) 서버가 특정 데이터에 대한 요청을 받는다.
  - (2-1) 우선 캐시 서버에 가서 데이터가 캐시에 있다면 캐시에서 데이터를 읽는다.
  - (2-2) 데이터가 캐시에 없으면 데이터베이스에서 해당 데이터를 읽고, 캐시에 쓴다.
  - (3) 응답 반환

> 위 단계를 Read-Through Cache Strategy(읽기 주도형 캐시 전략)이라고 한다.

### 캐시 사용 시 유의할 점

- 캐시가 바람직한 상황

  - 데이터 갱신은 자주 일어나지 않지만, 참조는 빈번하게 일어난다면 고려해볼만 하다.

- 캐시에 두어야 하는 데이터들의 성격

  - 캐시는 데이터를 휘발성 메모리에 두기에, 영속적으로 보관할 데이터를 두기에 바람직하지 않다.  
    예를 들어, 캐시 서버가 재시작되면 캐시 내의 모든 데이터는 사라진다. 중요 데이터는 여전히  
    지속적 저장소(Persistent Data Store)에 저장되어 있다.

- 일관성(Consistency) 유지 전략

  - 일관성은 데이터 저장소의 원본과 캐시 내의 사본이 같은지의 유무를 말한다.  
    저장소의 원본을 갱신하는 연산과 캐시를 갱신하는 연산이 단일 트랜잭션으로 처리되지 않는 경우,  
    일관성이 깨질 수 있다. 특히 여러 지역에 걸쳐 시스템을 확장해가는 경우, 캐시와 저장소 사이의  
    일관성을 유지하는 게 꽤나 어려운 문제가 된다.

- 장애 대처 방안

  - 캐시 서버를 한 대만 두는 경우, 해당 서버가 SPOF가 될 수 있다. 역시나 여러 지역에 걸쳐 캐시 서버를  
    분산시키는 것이 답이다.

- 캐시 메모리의 추산 방식

  - 캐시 메모리가 너무 작으면 액세스 패턴에 따라 데이터가 너무 자주 캐시에서 밀려나(eviction), 성능이  
    떨어지게 된다. 이를 막을 한 가지 방법은 캐시 메모리를 과할당(overprovisioning)하는 것이다.

- 데이터 방출(eviction) 정책의 결정

  - 캐시가 가득 찬 상태에서 추가로 데이터를 넣어야 하는 경우에 대한 정책을 의미한다.  
    가장 널리 쓰이는 것은 LRU(Least Recently Used) 방식으로, 사용된 시점이 가장 오래된 데이터를 내보내는 정책이다.  
    다른 정책으로는 LFU(Least Frequently Used) 방식, FIFO(First In First Out) 방식 등이 있다.

<hr/>

## CDN(Content Delivery Network)

- **CDN** : 정적 컨텐츠를 전송할 때 쓰이는, 지리적으로 분산된 서버의 네트워크.  
  예를 들어 이미지, 비디오, CSS, JS 파일 등을 캐시할 수 있다.

### CDN 사용 시의 고려 사항

- 비용: 자주 사용되지 않는 컨텐츠는 굳이 캐싱하여 얻는 이득이 크지 않으므로, CDN에서 제외해 비용을 최적화하자.

- 적절한 만료 시한 설정: 시의성이 중요한(time-sensitive) 컨텐츠의 경우, 만료 시간을 잘 정하자.  
  너무 길면 컨텐츠의 신선도가 떨어지며, 너무 짧으면 원본 서버에 빈번히 접속하게 될 수 있다.

- CDN 장애에 대한 대처 방안: CDN 자체가 죽었을 경우, 웹사이트 또는 애플리케이션 등이 어떻게 동작해야 할지 고려해야 한다.  
  예를 들어 일시적으로 CDN이 응답하지 않을 경우, 해당 문제를 감지해 원본 서버로부터 직접 컨텐츠를 가져오도록  
  클라이언트를 구성하게 해야 할 수 있다.

- 컨텐츠 무효화(invalidation) 방법 : 아직 만료되지 않은 컨텐츠라도, 아래 방법들 중 하나를 쓰면 CDN에서 제거할 수 있다.

  - CDN Service Provider가 제공하는 API 이용
  - 컨텐츠의 다른 버전을 서비스하도록 Object Versioning 사용

<hr/>
