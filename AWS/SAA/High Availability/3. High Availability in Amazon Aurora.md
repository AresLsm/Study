# High Availability in Amazon Aurora

## Amazon Aurora HA Options

### Amazon Aurora

- AWS's fastest growing service
- Database service with superior MySQL and PostgreSQL engine compliant service
- Seperates the compute layer from the storage layer

![picture 3](/images/AWS_SAA_HAAA_1.png)

### Data Management RDS vs Aurora

- When compared with RDS, the management of data from a **replication** viewpoint is fundamentally different
- In RDS, data needs to be **replicated** from the **master** to each of its **replicas**
- Aurora on the other hand has **no need for replication** since it uses and shares a **single logical volume**  
  amongst all compute instances.

### Aurora Data Consistency

- Aurora uses a **quorum and gossip protocol** baked within the storage layer to ensure that the data remains consistent.
- Together, the quorum and gossip protocol provide a continuous **self healing** mechanism for the data.

> Read quorom: 3, Write quorum: 4

- The peer to peer gossip protocol is used to ensure that data is copied across each of the 6 storage nodes.

- Aurora in general, and regardless of the compute layer setup, always provides **6 way replicated storage across**  
  **3 AZs.**

- Because of Aurora's storage layer design, Aurora is only supported in regions that have **3 or more** AZs.

- Aurora provides both automatic and manual failover of the master either of which takes approximately 30secs to complete.

- In the event that Aurora detects a master going offline, Aurora will either launch a replacement master or promote an  
  existing read replica to the role of master, with the latter being the preferred option as it is quicker for this  
  promotion to complete.

### Connection Endpoints

![picture 4](/images/AWS_SAA_HAAA_2.png)

- There are 4 different connection endpoint types.

- Cluster Endpoint

  - The cluster endpoint points to the current master database instance. Using the Cluster Endpoint allows your  
    application to perform read and writes against the master instance.

- Reader Endpoint

  - The reader endpoint load balances connections across the read replica fleet within the cluster.

- Custom Endpoints

  - Custom endpoints can be used to **group instances** based on instance size or maybe group them on a particular  
    db parameter group.
  - You can then **dedicate the custom endpoint** for a specific role or task within your organization.  
    ex) A requirement to generate month end reports - You can connect to a custom endpoint **specifically for this task**.

- Instance Endpoint

  - Instance endpoint maps directly to a **cluster instance.** Each and every cluster instance has its own instance  
    endpoint. You can use instance endpoint when you want **fine grained control** over which instance you need to  
    service your requests.

- General Points

  - **Read intensive** workloads should connect via the **reader endpoint**.
  - Reader and Custom connection endpoints are designed to **load balance** connections across their members.
  - Connection endpoint load balancing is implemented internally using **Route53 DNS.**
  - Be careful in the client layer **not to cache** the connection endpoint lookups longer than their specified TTLs.
  - Connection endpoints are mostly applicable and used in **Single Master with Multiple Read Replica** setups.

---

## Aurora Single Master - Multiple Read Replicas

![picture 5](/images/AWS_SAA_HAAA_3.png)

- Replication of data is performed **asynchronously** in milliseconds, fast enough to give the impression that  
  replication is happening synchronously.

![picture 6](/images/AWS_SAA_HAAA_4.png)

- Read replicas share the **same underlying storage layer** connected to the master.
- Read replicas can be deployed in **different AZs within the same VPC** or if required, can be launched as  
  **cross region replicas.**
- Each read replica can be tagged with a label, indicating priority in terms of which one gets promoted to the role of  
  master in the event of the master going down.
- The master can be rebooted in 60 or less seconds.

### Properties

- This type of cluster supports being stopped and started manually in its entirety.
- When you stop and start a cluster, all underlying compute instances are either stopped or started.
- When stopped, the cluster remains stopped for up to 7 days, after which it will automatically restart.
- Daily backups are automatically performed with a default retention period of 1 day, and for which can be adjusted  
  up to a maximum retention period of 35 days.
- Additionally on-demand manual snapshots can be performed on the database at any time.
- Manual snapshots are stored indefinitely until you explictly choose to delete them.  
  Restores are performed into a new database.

---

## Aurora Multi Master

- An Aurora multi-master setup allows you to configure a pair of masters in an active-active read-write configuration,  
  which can later be scaled up on demand by the customer to a maximum of four masters.

- In this configuration, you can read and write to any of the provisioned master instances, providing  
  improved fault tolerance within the compute layer.

![picture 7](/images/AWS_SAA_HAAA_5.png)

- The configuration deploys an active-active pair of compute instances with each instance being deployed  
  in its own availability zone.

- If an instance outage occurs in one availability zone, all database writes can be redirected to the remaining  
  active instance managed by the customer in the client-side logic, and all without the need to perform a failover.  
  This also provides protection from az outages.

- In multi-master configuration, you cannot add additional read replicas into the cluster.

- Incoming database connections to an Aurora multi-master cluster are **not load balanced** by the service.

- **Load balancing** connection logic **must be implemented and performed within the client.**

---
