# 구글 드라이브 설계

- 설계에 들어가기 앞서 일단 구글 드라이브가 어떤 서비스인지 알아보자.  
  구글 드라이브는 파일 저장 및 동기화 서비스로 문서, 사진, 비디오, 기타 파일을 클라우드에 보관할 수 있도록 한다.  
  이 파일은 컴퓨터, 스마트콘, 태블릿 등 어떠한 단말에서도 이용 가능해야 한다. 아울러 보관된 파일은 친구, 가족, 동료 등  
  다른 사용자와 손쉽게 공유할 수 있어야 한다.

## 문제 이해 및 설계 범위 확정

> 구글 드라이브를 설계하는 것은 매우 큰 프로젝트이니, 질문을 통해 설계 범위를 좁히도록 하자.

- 아래는 가장 중요하게 지원해야할 기능 및 요구사항이다.

  - 가장 중요하게 지원해야 할 기능: 파일 업로드/다운로드, 파일 동기화, 알림
  - 모바일 앱, 웹 앱 모두 지원
  - 파일 암호화가 필요하다.
  - 파일 크기는 10GB의 제한이 있다.
  - DAU는 1000만이다.

- 이번 장에서는 아래 기능들의 설계에 집중할 것이다.

  - 파일 추가: ex) drag-and-drop
  - 파일 다운로드
  - 여러 단말에 파일 동기화. 한 단말에서 파일을 추가하면 다른 단말에도 자동으로 동기화되어야 한다.
  - 파일 갱신 이력 조회(revision history)
  - 파일 공유
  - 파일이 편집되거나 삭제되거나 새롭게 공유되었을 때 notification

- 이번 장에서 다루지 않을 기능들은 아래와 같다.

  - Google Docs 편집 및 협업 기능

- 기능적 요구사항 이외에 아래의 비 기능적 요구사항을 이해하는 것도 중요하다.

  - 안정성: 저장소 시스템에서 안정성은 아주 중요하다. 데이터 손실은 발생하면 안된다.
  - 빠른 동기화 속도: 파일 동기화에 시간이 너무 많이 걸리면 UX를 매우 손상시킬 것이다.
  - 네트워크 대역폭: 이 제품은 네트워크 대역폭을 불필요하게 많이 소모하면 안된다. 이또한 UX를 해칠 수 있다.
  - 규모 확장성: 이 시스템은 아주 많은 양의 트래픽도 처리할 수 있어야 한다.
  - 높은 가용성: 일부 서버에 장애가 발생하거나, 느려지거나, 네트워크 일부가 끊겨도 시스템은 계속 사용 가능해야 한다.

### 개략적 추정치

- 가입 사용자는 5000만명이고, DAU는 1000만명이다.
- 모든 사용자에게 10GB의 무료 저장 공간을 할당할 수 있어야 한다.
- 매일 각 사용자가 평균 2개의 파일을 업로드한다고 가정한다. 각 파일의 평균 크기는 500KB 이다.
- 읽기, 쓰기 연산의 비율은 1:1이다.
- 필요한 저장공간의 총량은 `5000만 사용자 * 10GB = 500Petabyte` 이다.
- 업로드 API의 QPS는 `1천만 사용자 * 2회 업로드 / 24시간/3600초 = 약 240` 이다.
- 최대 QPS는 `QPS * 2 = 480` 이다.

---

## 개략적 설계안 제시 및 동의 구하기

- 이번에는 모든 것을 담은 한 대의 서버에서 출발해 점진적으로 천만 사용자 지원이 가능한 시스템으로 발전시켜 나가보자.

- 우선 아래와 같은 구성의 서버 한 대로 시작해보자.

  - 파일을 올리고 다운로드 하는 과정을 처리하는 웹 서버
  - 사용자 데이터, 로그인 정보, 파일 정보 등의 메타데이터를 보관할 데이터베이스
  - 파일을 저장할 저장소 시스템. 파일 저장을 위해 1TB의 공간을 사용할 것이다.

- 몇 시간 정도 들여서 Apache Web Server를 설치하고, MySQL Database를 깔고, 업로드되는 파일을 저장할 `drive/`라는 디렉토리를 준비한다.  
  `drive/` 디렉토리 하위에는 namespace라 불리는 하위 디렉토리들을 둔다. 각 namespace 내에는 특정 사용자가 올리는 파일들이 보관된다.  
  이 파일들은 원래 파일명과 같은 이름을 갖는다. 각 파일과 폴더는 그 상대 경로를 namespace 이름과 결합하면 unique하게 식별해낼 수 있다.

- 아래 그림은 `drive/` 디렉토리에 실제 파일이 보관된 사례를 나타낸다.

![picture 5](/images/SDI_GD_1.png)

### API

- 이 시스템은 어떤 API를 제공해야 할까? 기본적으로 3개의 API가 필요하다.  
  파일 업로드 API, 파일 다운로드 API, 그리고 파일 갱신 히스토리 제공 API이다.

#### 1. 파일 업로드 API

- 이 시스템은 두 가지 종류의 업로드를 제공한다.

  - 단순 업로드: 파일 크기가 작을 때 사용한다.
  - Resumable upload: 파일 사이즈가 크고 네트워크 문제로 업로드가 중단될 가능성이 높다고 생각되면 사용한다.

- Endpoint: `/files/upload?uploadType=resumable`

- 인자

  - uploadType=resumable
  - data: 업로드할 로컬 파일

- Resumable upload는 아래의 세 단계 절차로 이뤄진다.

  - Resumable upload URL을 받기 위한 최초 요청 전송
  - 데이터를 업로드하고 업로드 상태 모니터링
  - 업로드에 장애가 발생하면 장애 발생 지점부터 업로드를 재시작

#### 2. 파일 다운로드 API

- Endpoint: `/files/download`

- 인자

  - path: 다운로드 할 파일의 경로

    ```json
    {
      "path": "/recipes/soup/best_soup.txt"
    }
    ```

#### 3. 파일 갱신 히스토리 API

- Endpoint: `/files/list_revisions`

- 인자

  - path: 갱신 히스토리를 가져올 파일의 경로
  - limit: 히스토리 길이의 최대치

  ```json
  {
    "path": "/recipes/soup/best_soup.txt",
    "limit": 20
  }
  ```

- 지금까지 본 모든 API는 사용자 인증을 필요로 하고 HTTPS 프로토콜을 사용해야 한다.  
  SSL(Secure Socket Layer)를 지원하는 프로토콜을 이용하는 이유는 클라이언트와 백엔드 서버가 주고받는 데이터를 보호하기 위함이다.

### 한 대 서버의 제약 극복

- 업로드되는 파일이 많아지다 보면, 결국에는 파일 시스템이 가득 차게 된다.

- 파일 시스템의 여유 공간이 정말 조금 남은 상황이 되었다고 가정해보자. 이렇게 되면 사용자는 더 이상 파일을 올릴 수 없게 되므로,  
  긴급히 문제를 해결해야 한다. 가장 먼저 떠오르는 해결책은 데이터를 sharding해 여러 서버에 나누어 저장하는 것이다.  
  아래 그림은 `user_id`를 기준으로 sharding한 예시이다.

![picture 6](/images/SDI_GD_2.png)

- 더 나아가 업계 최고 수준의 규모 확장성, 가용성, 보안, 성능을 제공하는 객체 저장소 서비스인 Amazon S3를 도입하기로 했다 해보자.  
  S3는 replication을 지원하는데, 같은 region 내에서 replication을 할 수도 있고 여러 region에 걸쳐 replication을 할 수도 있다.  
  AWS 서비스 region은 AWS가 데이터 센터를 운영하는 지리적 영역이다. 아래 그림에서 볼 수 있듯이, 데이터 replication을 할 때는 같은  
  region 내에서만 할 수도 있고, 여러 region에 걸쳐서도 할 수 있다. 여러 region에 걸쳐 replication을 하면 데이터의 손실을 막고  
  가용성을 최대한 보장할 수 있으므로 이렇게 하기로 하자.

![picture 7](/images/SDI_GD_3.png)

- 파일을 S3에 넣고 나니, 저장 공간 부족으로 인한 데이터 손실 등의 장애는 더 이상 발생하지 않을 것이다.  
  조금 더 개선할 부분들을 보자.

  - Load balancer: 네트워크 트래픽을 분산하기 위해 load balancer를 사용한다. Load balancer는 트래픽을 고르게 분산할 수 있을  
    뿐만 아니라, 특정 웹 서버에 장애가 발생하면 자동으로 해당 서버를 우회해준다.

  - Web server: Load balancer를 추가하고 나면 더 많은 웹 서버를 손쉽게 추가할 수 있다. 따라서 트래픽이 폭증해도 쉽게 대응이 가능하다.

  - Metadata Database: 데이터베이스를 파일 저장 서버에서 분리해 SPOF를 회피한다. 아울러 replication과 sharding 정책을 사용해  
    가용성과 규모 확장성 요구사항에 대응한다.

  - File storage: S3를 파일 저장소로 사용하고 가용성과 데이터 무손실을 보장하기 위해 2개 이상의 region에 데이터를 replicate 한다.

- 이 모든 부분을 개선하고 나면 web server, metadata database, file storage가 한 대의 서버에서 여러 서버로 잘 분리되었을 것이다.  
  아래 그림은 이에 맞게 수정된 설계안이다.

![picture 8](/images/SDI_GD_4.png)

### 동기화 충돌

- 구글 드라이브와 같은 대형 저장소 시스템의 경우, 때때로 동기화 충돌이 발생할 수 있다.  
  이를테면 두 명 이상의 사용자가 같은 파일이나 폴더를 동시에 업데이트하려고 하는 경우이다. 이런 충돌은 어떻게 해소할 수 있을까?  
  여기서는 다음의 전략을 선택할 것인데 먼저 처리되는 변경은 성공한 것으로 보고, 나중에 처리되는 변경은 충돌이 발생한 것으로 표시하는 것이다.

![picture 9](/images/SDI_GD_5.png)

- 위 그림에서 사용자1과 사용자2는 같은 파일을 동시에 갱신하려 한다. 하지만 이 시스템은 사용자1의 파일을 먼저 처리했다.  
  따라서 사용자1의 파일 갱신 시도는 정상적으로 처리되지만, 사용자2에 대해서는 동기화 충돌 오류가 발생할 것이다.  
  그럼 이 오류는 어떻게 해결해야 할까? 오류가 발생한 시점에 이 시스템에는 같은 파일의 두 가지 버전이 존재하게 된다.  
  즉, 사용자2가 갖고 있는 local copy와 서버에 있는 최신 버전이다. 이 상태에서 사용자는 두 파일을 하나로 합칠지, 아니면 둘 중  
  하나를 다른 파일로 대체할지를 결정해야 한다.

### 개략적 설계안

- 아래 그림은 이번에 구축할 구글 드라이브의 개략적 설계안이다.

![picture 10](/images/SDI_GD_6.png)

- 각 컴포넌트에 대해 조금 더 자세히 알아보자.

  - 사용자 단말: 사용자가 이용하는 웹 브라우저나 모바일 앱 등의 클라이언트
  - 블록 저장소 서버(Block server): 파일 블록을 클라우드 저장소에 업로드하는 서버다. 블록 저장소는 블록 수준 저장소(block-level storage)라고도  
    하며, 클라우드 환경에서 데이터 파일을 저장하는 기술이다. 이 저장소는 파일을 여러 개의 블록으로 나눠 저장하며 각 블록에는 고유한 hash값이 할당된다.  
    이 hash값은 Metadata database에 저장된다. 각 블록은 독립적인 객체로 취급되며, 클라우드 저장소 시스템(S3)에 보관된다.  
    파일을 재구성하려면 블록들을 원래 순서대로 합쳐야 한다.

  - 클라우드 저장소: 파일은 블록 단위로 나뉘어져 클라우드 저장소에 보관된다.
  - 아카이빙 저장소(Cold storage): 오랫동안 사용되지 않은 inactive 데이터를 저장하기 위한 컴퓨터 시스템이다.
  - Load balancer: 요청을 모든 API server에 고르게 분산하는 역할을 한다.
  - API Server: 파일 업로드 외의 거의 모든 것을 담당하는 서버다. 사용자 인증, 프로필 관리, 파일 메타데이터 갱신 등에 사용된다.
  - Metadata Database: 사용자, 파일, 블록, 버전 등의 메타데이터 정보를 관리한다. 실제 파일은 클라우드에 보관하며, 이 데이터베이스에는  
    오직 메타데이터만 둔다는 것을 명심하자.
  - Metadata Cache: 성능을 높이기 위해 자주 쓰이는 메타데이터는 cache한다.
  - 알림 서비스: 특정 이벤트가 발생했음을 클라이언트에게 알리는 데 쓰이는 publish/subscribe 프로토콜 기반 시스템이다.  
    이 설계안에서는 클라이언트에게 파일이 추가되거나, 편집되거나, 삭제되었음을 알려 파일의 최신 상태를 확인하도록 하는 데 쓰인다.
  - 오프라인 사용자 백업 큐(offline backup queue): 클라이언트가 접속 중이 아니라서 파일의 최신 상태를 확인할 수 없을 때는 해당 정보를 이 queue에  
    두어 나중에 클라이언트가 접속했을 때 동기화할 수 있도록 한다.

---
