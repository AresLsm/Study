# Streaming Data

## Fundamentals of Stream Processing

### Batch Processing

- Data is collected, stored, and analayzed in chunks of a fixed size on a regular schedule.
- The schedule depends on the **frequency of data collection** and the **related value of the insight gained.**

> Value: At the center of stream processing.

### Addressing the Shortcomings of Batch Processing

- Some data are only valuable at a particular moment.

- Problems of Batch Processing

  - (1) Batch processing systems split data into time intervals that are consistent and evenly spaced,  
    which creates a steady workload that is predictable. While it is predictable, **it has no intelligence.**

  - (2) Batch processing systems are also designed to wait until a specific amount of data is accumulated before  
    processing starts. This leads to inconsistent time period in each batch of data.

### Stream Processing

- Stream Processing was created to address issues of latency, session boundaries, and inconsistent load.

- The term _streaming_ is used to describe information as it flows continuously without a beginning or end.

- Data sources for stream can be applications, networking devices, server log files, web activities,  
  location data and much more. All of these can be aggregated in real-time to respond and perform analysis  
  from a single source of truth.

- Stream processing is acting on, or reacting to data while it is in motion.  
  **Computation** happens in the moment data is produced or received.

- When receiving an event from the stream, a stream processing application _reacts_ to it. This reaction might be  
  to trigger an action, update an aggregate or similar statistic, or cache an event for future reference.

### Stream Application

- A stream application consists of three parts:
  - Producer: Collects events and transactions and put into the Data Stream.
  - Data Stream: Stores the data itself.
  - Consumer: Access the Data Streams, read the data and then act on it.

### Benefits of using Streaming Data

- When dealing with never-ending data

  - Best processed while it is in-flight
  - Batch processing is built around a **data-at-rest architecture**: before processing can begin, the collection  
    has to be stopped, and the data must be stored.
  - Subsequent batches of data bring with them the need to aggregate data across multiple batches.  
    In constrast, streaming architectures handle never-ending data streams naturally with grace.
  - Using streams, patterns can be detected, results inspected, and multiple streams can be examined simultaneously.

- When dealing with limited storage capacity

  - Sometimes, the volume of data is larger than the existing storage capacity.
  - Using streams, the raw data can be processed in real-time and then retain only the information and insight  
    that is useful.

- When dealing with time-series data

  - Stream processing naturally fits with time-series data and the detection of patterns over time.
  - For example, when trying to detect a sequence such as the length of a web session in a continous stream of data,  
    it would be difficult to do in batches.
  - Time series data, such as that produced by IoT sensors, is the most continuous type of data that can be streamed.
  - IoT devices are a natural fit into a streaming data architecture.

- Reactions in Real-Time

  - Almost no lag time in between when events happen, insights are derived, and actions are taken.
  - Actions and analytics are up-to-date and reflect data while it is still fresh, meaningful, and valuable.

- Decoupled Architectures improve operational efficiency

  - Streaming reduces the need for large and expensive shared databases: each stream processing application  
    maintains its own data and state, which is made simple by the stream processing framework.
  - Stream processing fits naturally inside a microservices architecture.

---

## Amazon Kinesis Overview

- Amazon Kinesis was designed to address the complexity and costs of streaming data into the AWS cloud.  
  It enables you to process event logs, social media feeds, clickstream data, application data, and IoT sensor data  
  in real time or near real time.

- Amazon Kineses is composed of 4 components:

  - Kinesis Video Streams: Used to stream processing on binary-encoded data such as audio and video.

  - The rest below are used to stream base64 text-encoded data.
    - Kinesis Data Streams
    - Kinesis Data Firehose
    - Kinesis Data Analytics

### Layers of Streaming

- Streaming applications are described as having five layers:
  - Source
  - Stream Ingestion
  - Stream Storage
  - Stream Processing
  - Destination

![picture 6](/images/AWS_SAA_SD_1.png)

- Data is generated by one or more **sources** including mobile devices, meters in smart homes, click streams,  
  IoT sensors, or logs.

- At the **Stream Ingestion Layer** data is collected by one or more Producers, formatted as Data Records,  
  and put into a stream.

- The Kinesis Data Stream is a **Stream Storage Layer** and is a high-speed buffer that stores data for between  
  a minimum of 24 hours and, as of November 2020, 365 days. 24 hours is the default.

- Inside Kinesis Data Streams, the Data Records are immutable. Once stored, they cannot be modified.  
  Updates to data require a new record to be put into the stream. Data is also not removed from the stream,  
  it can only expire.

- The **Stream Processing Layer** is managed by Consumers.  
  Consumers are also known as Amazon Kinesis Data Streams Applications and process data contained inside a stream.

- Consumers send Data Records to the **Destination Layer**.  
  This can be something like a Data Lake, a Data Warehouse, durable storage, or even another stream.

### Kinesis Video Streams

- Designed to stream binary-encoded data into AWS from millions of sources
  (mostly audio and video, but it can be any type of binary-encoded time-series data)

- The AWS SDKs make it possible to securely stream data to AWS for playback, storage, analytics, machine learning  
  and other processing.

- Data can be ingested from smartphones, security cameras, edge devices and much more.

- Kinesis Video Streams supports the WebRTC, which allows for two-way real-time media streaming between  
  web browsers, mobile applications, and connected devices.

### Kinesis Data Streams

- A highly-customizable streaming solution available from AWS.
- Highly Customizable:
  - All parts involved with stream processing - data ingestion, monitoring, scaling, elasticity, and consumption  
    are done programmatically when creating a stream.
- AWS will provision resources only when requested.
- **Does not have the ability to do Auto Scaling**

- A Kinesis Data Stream is a set of **shards**, which contains a sequence of data records.  
  Data records are composed of a sequence number, partition key, and data blob.(immutable)

- Two types of consumers of Kinesis Data Streams

  - Classic: Pulls data from the stream, also known as a **polling mechanism**.
  - Enhanced Fan Out: Uses push method, allowing consumers to subscribe to a shard.  
    Results in data are pushed automatically from the shard into a consumer application.  
    Since conumers are not pulling the data, shard limits are removed - every consumer gets 2mbps of  
    provisioned throughput per shard.

### Kinesis Data Firehose

- Data Firehose, being fully managed, is a streaming delivery service for data.

- Ingested data can be dynamically transformed, scaled automatically, and is automatically delivered to a data store.

- It is NOT a streaming storage layer in the way that Kinesis Data Stream is.

- Data Firehose uses producers to load data into streams in batches.  
  Once inside the stream, the data is delivered to a data store.

- Unlike Kinesis Data Streams, Amazon Kinesis Data Firehose buffers incoming streaming data before delivering  
  it to its destination. The buffer size and buffer interval is chosen when creating a delivery stream.  
  The buffer size is in megabytes and has different ranges depending on the destination.  
  The buffer interval can range from 60 seconds to 900 seconds.  
  Essentially, data buffers inside the stream and will leave the buffer when it is either full or when the  
  buffer interval expires. For this reason, Kinesis Data Firehose is considered a _near real-time_ streaming solution.

- Kinesis Data Firehose can also invoke Lambda functions to transform incoming source-data and deliver the  
  transformed data to its destination.

- There is no free tier for using Kinesis Data Firehose.  
  However, costs are only incurred when data is inside a Firehose stream.  
  There is no bill for provisioned capacity, only used capacity.

### Kinesis Data Analytics

- Kinesis Data Analytics has the ability to read from the stream in real time and do aggregation and analysis  
  on data while it is in motion.

- It does this by leveraging SQL queries or with Apache Flink using Java or Scala to perform time-series  
  analysis, feed real-time dashboards, and create real-time metrics.

- When using Kinesis Data Firehose with Kinesis Data Analytics, data records can be only queried using SQL.  
  Apache Flink with Java and Scala apps are only available for Kinesis Data Streams.

- Has built-in templates and operator for common processing functions to organize, transform, aggregate,  
  and analyze data at scale. Use cases include ETL, the generation of continuous metrics, and doing  
  responsive real-time analytics.

---
