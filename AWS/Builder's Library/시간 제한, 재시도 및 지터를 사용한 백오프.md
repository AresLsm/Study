# 시간 제한, 재시도 및 지터를 사용한 백오프

- <a href="https://aws.amazon.com/ko/builders-library/timeouts-retries-and-backoff-with-jitter/?did=ba_card&trk=ba_card">Amazon Builder's Library: Timeout, Retries, Backoff and Jitter</a>

## 장애 발생 및 복원력

- 서비스는 서버, 네트워크, 로드 밸런서, 운영자의 실수까지 등 많은 요인들로부터 장애가 발생할 수 있다.  
  장애 가능성이 낮은 시스템을 설계할 수 있으나, 결코 실패하지 않는 시스템을 구축하는 것은 불가하다.

> - 복원력: 시스템의 장애 가능성을 줄이고, 실패를 허용하는 시스템을 설계해 **작은 규모의 장애가 전면적인 가동 중단으로 확대되는 것을 방지하는 능력**

- AWS에서는 _복원력_ 이 우수한 시스템을 구축하기 위해 **시간 제한, 재시도, 백오프** 를 제시한다.

- 이 각각을 AWS에서는 어떻게 처리하는 지에 대해 보기전에, 개념을 간단히 훑어보자.

### 시간 제한

- 수많은 장애 유형은 **요청이 평소보다 오래 걸리고 완료되지 않을 때** 명확히 확인된다.  
  요청이 오래 걸리면 클라이언트는 요청을 위한 리소스를 오랜 시간 붙잡고 이써야 하고, 서버에서도 마찬가지로 리소스 부족 현상이  
  발생할 수 있다. 이러한 문제를 해결하기 위해 클라이언트는 **시간 제한**을 설정한다.  
  이는 즉 **클라이언트가 요청이 완료될 때까지 기다리는 최대 시간** 이다.

### 재시도

- 실패한 요청을 동일하게 다시 시도했을 때 성공하는 경우도 있지만, *부분적이거나 일시적인 장애*가 더 발생하기 쉽다.

  - **부분적인 장애** : 일정 비율의 요청이 성공하는 것
  - **일시적인 장애** : 잠시 동안 모든 요청이 실패하는 것

- **재시도** : 클라이언트가 동일한 요청을 다시 전송해 부분적인 장애와 단기적인 일시적 장애 상황을 해결하는 방법

- 하지만 재시도가 항상 안전하진 않다. 시스템이 오버로드에 가까워져 이미 장애가 발생한 경우, 재시도로 인해 호출 중인 시스템의  
  로드가 증가할 수 있다. 이러한 문제를 방지하는 방법이 **백오프** 이다. 백오프를 사용하면 장애 이후 수행되는 재시도 간의  
  대기 시간이 증가해 백엔드의 부하가 일정하게 유지된다.

- 시스템 오버로드 뿐만 아니라, 재시도는 일부 원격 호출에 부작용이 수반된다는 문제점이 있다.  
  물론 이를 방지하는 가장 좋은 방법은 **API를 멱등하게 설계하여** 안전하게 재시도할 수 있도록 하는 것이다.

### 지터

- 시스템 부하로 인해 오류가 발생했을 때, 모든 클라이언트가 동시에 재시도하게 되므로 재시도가 비효율적일 수 있다.  
  이를 방지하기 위해 **지터** 를 적용한다.

- **지터** : 임의로 지정한 시간, 이 시간이 지나면 도착률을 분산시켜 대량의 burst를 방지하도록 요청을 작성하거나 재시도하게 된다.

<hr/>

## 시간 제한 (Timeout)

- AWS가 사용하는 모범 사례는 아래와 같다.

  - 모든 원격 호출, 심지어는 동일한 시스템의 경우에도 프로세스 간의 모든 호출에는 일반적으로 시간 제한을 설정한다.  
    (연결 시간 제한, 요청 시간 제한 모두 포함)

- 그렇다면 설정할 timeout 값은 어떻게 결정할까?  
  너무 높게 설정하면 클라이언트가 대기하는 시간 내에서도 리소스가 사용되기에 유용성이 떨어지고, 너무 낮게 설정하면  
  재시도 회수가 많아져 백엔드의 트래픽과 대기 시간이 증가하며, 모든 요청의 재시도가 시작되기에 백엔드의 규모가 작을 경우  
  지연 시간의 증가가 완전한 가동 중단을 일으킬 수 있다.

- AWS Region 내의 요청에 대한 timeout을 정하는 좋은 방법으로 AWS는 downstream service의 latency metric을  
  볼 것을 추천한다. 예를 들어보자. 하나의 서비스가 다른 서비스로 요청할 때, _허용 가능한 가짜 timeout의 비율_ 을 설정한다.  
  이 비율이 0.1% 라고 해보자. 그런 다음, 해당 요청을 처리하는 downstream service의 latency metric을 측정한다.  
  이 예시 상황에서는 p99.9 를 측정할 것이다. p99.9의 latency가 1초 라고 했다면, 이 경우 timeout은 1초로 설정할 것이다.

- 하지만 이 방식은 아래와 같은 몇 가지 함정 및 신경써야 할 점들이 있다.

  - 인터넷을 사용하는 등 클라이언트가 상당한 네트워크 대기시간을 갖게될 경우에는 부적합하다.  
    이러한 경우, 클라이언트가 전 세계에서 요청을 할 수 있음을 염두에 두고 합리적인 수준으로 최악의 네트워크 대기 시간까지 고려해야 한다.

  - latency의 범위가 좁은 서비스(예를 들어 p99.9와 p50이 별반 다를게 없는 경우)에는 적합하지 않다.  
    이런 서비스의 경우, 평균 latency에 전후로 시간을 조금 추가해 latency가 조금만 증가해서 timeout이 많이  
    발생하는 상황을 방지할 수 있다.

  - timeout을 구현할 때도 주의해야 할 점이 몇 가지 있다. Linux의 SO_RCVTIMEO는 강력하지만 단점 또한 있어 end-to-end  
    socket timeout으로 사용하기엔 좋지 않다. Java의 경우에는 timeout 제어 메커니즘을 드러내는 반면, Go 등의 언어에서는  
    보다 강력한 timeout 메커니즘을 제공한다.

  - timeout이 DNS 작업에 소요되는 시간, TLS Handshake에 소요되는 시간 등 원격 호출의 모든 과정을 포함하지 않는 경우가 있다.  
    AWS에서는 일반적으로 timeout을 결정할 때 socket 관련하여 소요되는 시간과 실제 작업 수행 시간을 파악하는 데 집중한다고 한다.

<hr/>

## 재시도(Retry)와 Backoff

### 재시도(Retry)

- **재시도**는 클라이언트가 더 높은 성공 확률을 얻기 위해 서버 시간을 사용하기에 _"이기적"_ 인 방식이기도 하다.  
  장애가 일시적이거나 드문 경우에는 크게 문제가 되지 않지만, 서버가 이미 overload한 상태에서의 재시도는  
  서버의 부하를 증가시켜 서버 전체에 대해 장애를 발생시킬 수 있기 때문이다.

> 재시도는 _강한 약물_ 과도 같다. 적정량을 쓰면 안전하지만, 과하게 사용할 경우 치명적인 손상을 입힐 수 있다.

### Backoff

- 위와 같은 재시도의 한계점 때문에, AWS에서는 **Backoff** 방식을 선호한다.  
  적극적이면서도 즉각적으로 재시도하는 대신, 클라이언트는 재시도 간에 **일정한 수준의 대기시간**을 유지한다.

- 아래는 Backoff의 패턴들 중 일부이다.

  - Exponential Backoff(지수 Backoff): **매 시도 후에 재기도 대기시간을 기하급수적으로 증가**시킨다.  
    단, 대기시간이 급증하기 때문에 매우 긴 backoff 시간으로 이어질 수 있다.

  - Capped Exponential Backoff(제한된 지수 Backoff): Exponential Backoff와 동일하지만,  
    Backoff의 최대 대기시간을 설정한다.

- 하지만 Backoff도 문제가 없는 것은 아니다.  
  모든 클라이언트가 일정 기간을 두고 재시도하기 때문에 서버가 overload 상태일 때 발생하는 재시도의 문제는 그대로 있다.

- 따라서 AWS가 채택하는 방법은 **클라이언트 재시도 회수를 제한하고, 서비스 지향 아키텍쳐에서 보다 빠른 시점에 장애(문제)를**  
  해결하는 것이다. 그리고 대부분의 클라이언트에는 자체적으로 timeout을 설정해 호출을 포기하게끔 한다.

### 재시도와 관련된 다른 문제들

- 분산 시스템에는 여러 계층(layer)들이 있는 경우가 많다. client의 호출로 인해 5개의 스택의 서비스가 호출된다고 해보자.  
  그리고 이 호출은 데이터베이스 query로 종료되며, 각 layer에는 3번의 재시도가 발생했다고 하자.  
  이런 상황에서 만약 부하가 이미 있을 때 데이터베이스 query가 실패하면 어떻게 될까?  
  각 layer는 독립적으로 재시도하기에 데이터베이스에 대한 부하가 243배 증가해 복구 가능성이 거의 사라지게 된다.  
  이는 각 layer의 재시도가 배수로 증가하기 때문이다. (3, 9, 27, 81, 243)  
  반면, 서비스 스택의 최상위 layer에 대해 재시도하게 된다면 이전 호출의 작업이 낭비되게 되어 효율성이 떨어진다.  
  일반적으로 저비용 제어 영역과 데이터 영역 작업을 위한 모범 사례는 **스택의 단일 지점에서 재시도**하는 것이다.

- 스택의 단일 지점에서 재시도하더라도, 오류가 시작될 때 트래픽이 대폭 증가하게 된다.  
  이를 완화하기 위해 오류의 임계값을 설정하고, 이 임계값을 초과할 때 downstream service에 대한 호출을 완전히  
  멈추는 **Circuit Breaker**를 적용하는 것이 권장된다. 하지만 Circuit Breaker는 테스트가 어려울 수 있는  
  _모달_ 동작을 시스템에 도입해야하기에 복구 시간이 크게 증가할 수 있다. AWS에서는 **Token Bucket**을 이용해  
  로컬에서 재시도를 제한하게 함으로써 이러한 위험을 완화한다. token이 있는 한 모든 호출을 재시도하고, token이 모두  
  소진되면 고정 속도로 재시도하게 한다.

- 일반적으로 AWS에서는 부작용을 수반하는 API가 **멱등성이 제공되지 않는다면 안전하지 않다**고 여긴다.  
  이러한 제한은 재시도 빈도와 관계없이 부작용이 딱 1번만 발생하게 한다. 대개의 읽기 전용 API는 멱등적이지만, 리소스를  
  생성하는 API는 그렇지 않을 수 있다. Amazon EC2 RunInstances API와 같은 일부 API는 명시적인 token 기반  
  메커니즘을 통해 멱등성을 제공하며, 이로 인해 안전한 재시도를 지원한다.  
  이렇게 중복된 부작용을 방지하기 위해서는 바람직한 API 설계와 함께 클라이언트 구현 시에도 여러 가지 사항을 주의해야 한다.

- 마지막으로, **장애가 발생했을 때 그 장애가 재시도할 가치가 있는지 파악**해야 한다. 예를 들어 HTTP는 client와  
  server 오류를 확실히 구분할 수 있다. Client 오류는 나중에도 성공하지 못할 것이기에 동일한 요청으로 재시도해서는  
  안되지만, server 오류는 후속 시도에서 성공할 수도 있다. 이는 이론적으로는 맞는 생각이지만, 시스템의 일관성은 이  
  경계를 모호하게 만드는 경우가 많다. 한 순간의 클라이언트 오류도 상태가 전파될 경우, 다음 순간에 성공으로 바뀔 수 있는 것이다.

- 위와 같은 문제점들에도 불구하고, 재시도는 일시적이면서도 무작위로 발생하는 오류에 대응해 고가용성을 제공하기 위한  
  강력한 메커니즘이다. 중요한 것은 **각 서비스에 대한 올바른 절충점을 찾는 것**이다. AWS는 항상 _"재시도는 이기적이다."_ 라는  
  것을 명심하고 구현해야 한다고 추천한다. 재시도는 클라이언트가 요청이 중요하다고 생각하고, 서비스가 더 많은 리소스를 사용해  
  요청을 처리하도록 요구하는 방식이다. 클라이언트가 너무 이기적이면, 넓은 범위에서 문제가 발생할 수 있다.

<hr/>

## Jitter

- 서버가 이미 리소스를 많이 쓰고 있을 때, Backoff는 사실상 큰 도움이 되지 못한다. 모든 실패한 호출이 동시에  
  backoff하게 되면, 재시도할 때 overload 또는 경합을 다시 야기할 수 있기 때문이다. 이에 대해 AWS가 제시하는  
  해결책은 Jitter이다.

- Jitter는 Backoff에 일정 수준의 임의성을 추가해 재시도가 시간을 두고 분산되게끔 한다.

- Jitter는 재시도만을 위한 것은 아니다. AWS의 운영 경험이 따르면, 제어 영역과 데이터 영역을 모두 포함하는  
  서비스에서 트래픽이 급증하는 경향이 있었다고 한다. 이런 트래픽 급증은 매우 짧아서 metric 지표에서 드러나지  
  않는 경우가 많다고 한다. 따라서 AWS에서는 시스템을 구축할 때 모든 타이머, 주기적인 작업 및 기타 지연된 작업에  
  약간의 jitter를 추가하는 것을 고려한다. 이를 통해 급증하는 업무를 분산하고, workload에 맞게 downstream  
  service를 보다 쉽게 확장할 수 있다.

- Scheduled Job에 Jitter를 추가할 때, AWS는 각 host에서 무작위로 jitter를 선택하지 않는다.  
  대신 동일한 host에서 매 시간마다 동일한 횟수로 생성되도록 일관된 방법을 사용한다고 한다.  
  예를 들어, 서비스가 overload되거나 race condition이 발생했을 때는 동일한 방식으로 패턴이 발생한다.  
  이런 패턴을 발견하고, 어떤 방식으로 처리할지는 사람이 직접 결정한다고 한다.

- 이 글의 저자는 Amazon EBS와 AWS Lambda의 경험을 공유해준다. 이 서비스들에서 저자는 client들이 1분에 1번과  
  같이 주기적으로 요청을 보내는 것을 파악했다. 만약 client가 이러한 주기적인 작업을 동일하게 하는 server가  
  여러 개 있을 경우, client에서는 요청을 정렬해 트리거할 수 있다. 저자는 초 단위의 부하에 집중해 client와  
  협력해 주기적인 worload에 jitter를 추가해서 server 용량은 줄이면서, 동일한 양의 작업을 처리할 수 있게  
  되었다고 한다.

- 결론적으로 트래픽 급증 현상에 대한 제어권은 줄지만, 고객이 트리거한 작업의 경우에도 고객 경험을 해치지 않는  
  수준에서 jitter를 추가하는 것이 바람직하다.

<hr/>
