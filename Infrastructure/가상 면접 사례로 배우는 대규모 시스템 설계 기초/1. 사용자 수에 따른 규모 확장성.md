# 사용자 수에 따른 규모 확장성

## 단일 서버

- 이전에는 웹, 앺, 데이터베이스, 캐시 등을 모두 한 대의 서버에서 실행했다.

<hr/>

## 데이터베이스

- 사용자가 늘면 서버 하나로는 충분하지 않아, 여러 서버를 둬야 한다.  
  예를 들어 하나는 웹 또는 모바일 트래픽 처리 용도로, 다른 하나는 데이터베이스용이다.  
  이렇게 웹 계층과 데이터 계층으로 분리하면, 그 각각을 독립적으로 확장해나갈 수 있다.

### 어떤 데이터베이스를 사용할까?

#### RDBMS(Relational Database Management System)

- MySQL, Oracle, PostreSQL 등의 RDBMS는 자료를 테이블과 row, column으로 표현한다.  
  SQL을 사용해 여러 테이블에 있는 데이터를 그 관계에 따라 join해 합칠 수 있다.

#### NoSQL Database

- Cassandra, Amazon DynamoDB 등 NoSQL은 비정형 데이터베이스다.  
  NoSQL은 다시 네 부류로 나눌 수 있다.

  - Key-Value Store
  - Graph Store
  - Column Store
  - Document Store

- 아래와 같은 경우에는 NoSQL(비관계형) 데이터베이스가 바람직한 선택일 수 있다.

  - 매우 낮은 latency의 요구
  - 다루는 데이터가 비정형(unstructured)이라 관계형 데이터가 아닌 경우
  - 데이터(JSON, YAML, XML 등)를 직렬화하거나(serialize) 역직렬화(deserialize)할 수 있기만 하면 되는 경우
  - 아주 많은 양의 데이터를 저장할 필요가 있는 경우

<hr/>

## 수직적 규모 확장 VS 수평적 규모 확장

- **수직적 규모 확장(Vertical Scaling)** : Scale Up이라고도 불리며, 서버에 고사양 자원(더 좋은 CPU, 더 많은 RAM 등)을  
  추가하는 행위.

- **수평적 규모 확장(Horizontal Scaling)** : Scale Out이라고도 불리며, 더 많은 서버를 추가해 성능을 개선하는 행위.

- 서버로 유입되는 트래픽 양이 적을 때 => **수직적 확장**

- 수직적 확장의 단점

  - 한계가 명확하다. 한 대의 서버에 CPU나 메모리를 무한대로 증설할 방법이 없다.
  - 장애에 대한 자동복구(failover) 방안이나 다중화(redundancy) 방안을 제시하지 않는다.

- 따라서 대규모 애플리케이션을 지원하는 데는 **수평적 확장**이 적합하다.

### 로드 밸런서(Load Balancer)

- **Load Balancer** : 부하 분산 집합(Load Balancing Set)에 속한 웹 서버들에게 트래픽 부하를 고르게 분산하는 역할

### 데이터베이스 다중화

- 서버와 마찬가지로 데이터베이스 역시 장애의 자동복구, 다중화를 지원하도록 해야 한다.  
  이를 위한 한 가지 방법을 보자.

- 데이터베이스 서버가 주(master)와 부(slave) 관계로 구성되며, 데이터 원본은 master에, 사본은 slave에 저장한다.  
  Write Operation은 master에서만 지원한다. Slave 들은 master로부터 그 사본을 전달받으며, read operation만을  
  지원한다. 예를 들어 INSERT, UPDATE, DELETE문은 모두 master로 전달되어야 한다.

- 대부분의 애플리케이션은 read 연산의 비중이 write 연산보다 훨씬 높다. 따라서 통상 slave의 수가 master보다 많다.

- 데이터베이스 다중화의 장점

  - **더 나은 성능** : master-slave 다중화 모델에서 모든 데이터 변경은 master로만 전달되는 반면,  
    read는 slave들로 분산된다. 병렬로 처리할 수 있는 query수가 늘어나므로, 성능이 좋아진다.

  - **안정성(Reliablity)** : 데이터베이스 서버 가운데 일부가 파괴되어도 데이터는 보존될 수 있다.

  - **가용성(Availability)** : 데이터를 여러 지역에 복제해둠으로써 하나의 데이터베이스 서버에  
    장애가 발생하더라도, 다른 서버에 있는 데이터를 가져와 계속 서비스할 수 있다.

- 로드밸런서가 시스템 가용성을 높이는 것처럼, 데이터베이스 중 하나가 다운되는 상황을 살펴보자.

  - slave가 하나 뿐인데 다운되었다면, read 연산은 한시적으로 모두 master로 전달된다. 또한 즉시 새로운 slave가  
    장애 서버를 대체하게 된다. slave가 여러 대인 경우에 read 연산은 나머지 slave들로 분산될 것이며, 새로운  
    slave가 장애 서버를 대체할 것이다.

  - master가 다운된다면, 한 대의 slave만 있는 경우에는 해당 slave가 새로운 master가 되며, 일시적으로  
    모든 데이터베이스 연산이 새로운 master에서 수행된다. 그리고 새로운 slave가 추가된다.  
    production 환경에서 벌어지는 일은 이보다 더 복잡한데, slave에 보관된 데이터가 최신 상태가 아닐 수 있기 때문이다.  
    없는 데이터는 복구 스크립트(recovery script)를 돌려 추가해야 한다. mutli-masters나 circular-replication 방식을  
    도입하면 이런 상황에 대처하는 데는 도움될 수 있지만, 해당 구성은 훨씬 더 복잡하다.

<hr/>

## 캐시

- **캐시(cache)** : 값비싼 연산 결과 또는 자주 참조되는 데이터를 메모리 내에 두고, 뒤이은 요청이 보다 빠르게  
  처리될 수 있도록 해주는 저장소

- 애플리케이션의 성능은 데이터베이스를 얼마나 자주 호출하느냐에 따라 크게 좌우되는데, 캐시는 그런 문제를 완화할 수 있다.

### 캐시 계층

- 캐시 계층(Cache Tier)은 데이터가 잠시 보관되는 곳으로, 데이터베이스보다 훨씬 빠르다.  
  별도의 캐시 계층을 두면 성능 개선 뿐만 아니라 데이터베이스의 부하 감소도 가능하며, 캐시 계층의 규모를 독립적으로  
  확장시키는 것도 가능하다.

- 아래는 캐시 서버를 두는 방법 중 하나다.

  - (1) 서버가 특정 데이터에 대한 요청을 받는다.
  - (2-1) 우선 캐시 서버에 가서 데이터가 캐시에 있다면 캐시에서 데이터를 읽는다.
  - (2-2) 데이터가 캐시에 없으면 데이터베이스에서 해당 데이터를 읽고, 캐시에 쓴다.
  - (3) 응답 반환

> 위 단계를 Read-Through Cache Strategy(읽기 주도형 캐시 전략)이라고 한다.

### 캐시 사용 시 유의할 점

- 캐시가 바람직한 상황

  - 데이터 갱신은 자주 일어나지 않지만, 참조는 빈번하게 일어난다면 고려해볼만 하다.

- 캐시에 두어야 하는 데이터들의 성격

  - 캐시는 데이터를 휘발성 메모리에 두기에, 영속적으로 보관할 데이터를 두기에 바람직하지 않다.  
    예를 들어, 캐시 서버가 재시작되면 캐시 내의 모든 데이터는 사라진다. 중요 데이터는 여전히  
    지속적 저장소(Persistent Data Store)에 저장되어 있다.

- 일관성(Consistency) 유지 전략

  - 일관성은 데이터 저장소의 원본과 캐시 내의 사본이 같은지의 유무를 말한다.  
    저장소의 원본을 갱신하는 연산과 캐시를 갱신하는 연산이 단일 트랜잭션으로 처리되지 않는 경우,  
    일관성이 깨질 수 있다. 특히 여러 지역에 걸쳐 시스템을 확장해가는 경우, 캐시와 저장소 사이의  
    일관성을 유지하는 게 꽤나 어려운 문제가 된다.

- 장애 대처 방안

  - 캐시 서버를 한 대만 두는 경우, 해당 서버가 SPOF가 될 수 있다. 역시나 여러 지역에 걸쳐 캐시 서버를  
    분산시키는 것이 답이다.

- 캐시 메모리의 추산 방식

  - 캐시 메모리가 너무 작으면 액세스 패턴에 따라 데이터가 너무 자주 캐시에서 밀려나(eviction), 성능이  
    떨어지게 된다. 이를 막을 한 가지 방법은 캐시 메모리를 과할당(overprovisioning)하는 것이다.

- 데이터 방출(eviction) 정책의 결정

  - 캐시가 가득 찬 상태에서 추가로 데이터를 넣어야 하는 경우에 대한 정책을 의미한다.  
    가장 널리 쓰이는 것은 LRU(Least Recently Used) 방식으로, 사용된 시점이 가장 오래된 데이터를 내보내는 정책이다.  
    다른 정책으로는 LFU(Least Frequently Used) 방식, FIFO(First In First Out) 방식 등이 있다.

<hr/>

## CDN(Content Delivery Network)

- **CDN** : 정적 컨텐츠를 전송할 때 쓰이는, 지리적으로 분산된 서버의 네트워크.  
  예를 들어 이미지, 비디오, CSS, JS 파일 등을 캐시할 수 있다.

### CDN 사용 시의 고려 사항

- 비용: 자주 사용되지 않는 컨텐츠는 굳이 캐싱하여 얻는 이득이 크지 않으므로, CDN에서 제외해 비용을 최적화하자.

- 적절한 만료 시한 설정: 시의성이 중요한(time-sensitive) 컨텐츠의 경우, 만료 시간을 잘 정하자.  
  너무 길면 컨텐츠의 신선도가 떨어지며, 너무 짧으면 원본 서버에 빈번히 접속하게 될 수 있다.

- CDN 장애에 대한 대처 방안: CDN 자체가 죽었을 경우, 웹사이트 또는 애플리케이션 등이 어떻게 동작해야 할지 고려해야 한다.  
  예를 들어 일시적으로 CDN이 응답하지 않을 경우, 해당 문제를 감지해 원본 서버로부터 직접 컨텐츠를 가져오도록  
  클라이언트를 구성하게 해야 할 수 있다.

- 컨텐츠 무효화(invalidation) 방법 : 아직 만료되지 않은 컨텐츠라도, 아래 방법들 중 하나를 쓰면 CDN에서 제거할 수 있다.

  - CDN Service Provider가 제공하는 API 이용
  - 컨텐츠의 다른 버전을 서비스하도록 Object Versioning 사용

<hr/>

## Stateless(무상태) 웹 계층

- 이번에는 웹 계층을 수평적으로 확장하는 방법에 대해 고민해보자.  
  이를 가능하게 하기 위해선 **상태 정보(사용자 세션 데이터 등)를 웹 계층에서 제거** 해야 한다.  
  바람직한 전략은 상태 정보를 RDBMS나 NoSQL 와 같은 지속성 저장소에 보관하고, 필요할 때  
  가져오도록 하는 것이다.

- 위처럼 구성된 웹 계층을 무상태 웹 계층이라 한다.

### 상태 정보 의존적인 아키텍쳐

- 상태 정보를 보관하는 서버와 그렇지 않은 서버 사이의 몇 가지 중요한 차이를 보자.  
  우선 상태 정보를 보관하는 서버는 클라이언트 정보, 즉 상태를 유지해 요청들 사이에 공유되도록 한다.  
  반면 무상태 서버에는 이런 장치가 없다.

- 세 개의 HTTP 요청을 처리하는 웹 서버가 있다고 하자. 그리고 세명의 사용자 A, B, C가 있다.  
  서버1에서 사용자 A의 요청을 처리한다면, 사용자 A의 세션 정보나 프로필 이미지 등의 상태 정보는  
  서버1에만 저장된다. 요청이 서버2로 전송되면 서버2에는 사용자 A에 대한 데이터가 없으므로 인증은 실패한다.  
  마찬가지로 B의 요청은 전부 서버2로, C의 요청은 서버3으로 전달되어야 한다.

- 위 상황의 문제는 같은 클라이언트로부터의 요청은 항상 같은 서버로 전송되어야 한다는 점이다. 대부분의 로드밸런서가  
  이를 지원하기 위해 _고정 세션(Sticky Session)_ 이라는 기능을 제공하지만, 이는 로드밸런서에 부담을 준다.  
  게다가 로드밸런서의 뒷단에 새로운 서버를 추가하거나 제거하기도 까다로워진다.

### 무상태 아키텍쳐

- 무상태 아키텍쳐에서는 사용자로부터의 HTTP 요청이 어떤 웹 서버로도 전달될 수 있다. 웹 서버는 상태 정보가 필요할 경우  
  공유 저장소(shared storage)로부터 데이터를 가져오면 된다. 따라서 상태 정보가 웹 서버로부터 물리적으로 분리되어 있다.  
  이러한 구조는 단순하고 안정적이며, 규모 확장 또한 쉽다.

- 세션 데이터를 웹 계층에서 분리하고 지속성 데이터 보관소에 저장한다고 했다. 이런 공유 저장소는 RDBMS일 수도 있고,  
  Memcached, Redis와 같은 캐시 시스템일 수도 있으며, NoSQL 일수도 있다.

<hr/>

## 데이터 센터

- 가용성을 높이고 전 세계 어디에서도 쾌적하게 사용할 수 있도록 하기 위해서는 여러 데이터 센터(Data Center)를  
  지원해야 한다.

- 두 개의 데이터 센터(DC1(Us-East), DC2(US-West))가 있다고 하자. 장애가 없는 상황에서 사용자는 가장 가까운  
  데이터 센터로 안내되는데, 통상적으로 이러한 절차를 지리적 라우팅(geoDS-Routing 또는 geo-routing)이라 한다.  
  지리적 라우팅에서의 geoDNS는 사용자의 위치에 따라 도메인 이름을 어떤 IP 주소로 변환할지 결정할 수 있도록 해주는  
  DNS 서비스다.

> 하나의 Data Center 내에는 WebServer, Database, Cache Server 등이 있다.  
> Load Balancer가 지리적 라우팅을 수행한다.

- 예를 들어, x%의 사용자는 US-East로, (100-x)% 의 사용자는 US-West 센터로 안내된다 하자. 이 상황에서  
  데이터 센터 중 하나에 심각한 장애가 발생하면, 모든 트래픽은 장애가 없는 데이터 센터로 전송된다.

- 하지만 이런 다중 데이터센터 아키텍쳐를 만들려면, 아래와 같은 기술적 난제를 해결해야 한다.

  - **트래픽 우회** : 올바른 데이터 센터로 트래픽을 보내는 효과적인 방법을 찾아야 한다. 예를 들어 GeoDNS는  
    사용자에게서 가장 가까운 데이터센터로 트래픽을 보낼 수 있도록 해준다.

  - **데이터 동기화(synchronization)** : 데이터 센터마다 별개의 데이터베이스를 사용하고 있는 상황이라면,  
    장애가 자동으록 복구되어(failover) 트래픽이 다른 데이터베이스로 우회된다 해도, 해당 데이터센터에는 찾는  
    데이터가 없을 수도 있다. 이러한 상황을 막는 보편적인 방법은 데이터를 여러 데이터센터에 걸쳐 다중화하는 것이다.

  - **테스트와 배포(deployment)** : 여러 데이터 센터를 사용하도록 시스템이 구성된 상황이라면, 웹 사이트 또는  
    애플리케이션을 여러 위치에서 테스트해보는 것이 중요하다. 한편, 자동화된 배포 도구는 모든 데이터 센터에 동일한  
    서비스가 설치되도록 하는 데 중요한 역할을 한다.

<hr/>

## 메시지 큐(Message Queue)

- 메시지 큐는 메시지의 무손실(durability), 비동기 통신(asynchronous communication)을 지원하는 컴포넌트다.

> Message Queue의 durability: 메시지 큐에 일단 보관된 메시지가 소비자(consumer)가 꺼낼 때까지 안전히 보관되는 특성

- 메시지 큐는 메시지의 buffer 역할을 하며, 비동기적으로 전송한다. 메시지 큐의 기본 아키텍쳐는 간단하다.  
  생산자(publisher or producer)라는 입력 서비스가 메시지를 만들어 메시지 큐에 발행(publish) 한다.  
  큐에는 보통 소비자(consumer or subscriber)라 불리는 서비스 혹은 서버가 연결되어 있는데, 메시지를 받아 그에 맞는 동작을  
  수행하는 역할을 한다.

- 메시지 큐를 이용하면 서비스 또는 서버 간의 결합이 느슨해져서, 규모 확장성이 보장되어야 하는 안정적인 애플리케이션을  
  구성하기 좋다. 생산자는 소비자 프로세스가 다운되어 있어도 메시지를 발행할 수 있고, 소비자는 생산자 서비스가 가용한  
  상태가 아니더라도 메시지를 수신할 수 있다.

- 메시지 큐를 사용하는 하나의 예시 상황을 생각해보자. 이미지의 cropping, sharpening, blurring 등을 지원하는 사진 보정  
  애플리케이션을 만든다고 해보자. 이러한 보정은 시간이 오래 걸릴 수 있는 프로세스이므로 비동기적으로 처리하면 편리하다.  
  작동 순서를 살펴보자.

  - (1) 웹 서버가 사진 보정 작업(job)을 메시지 큐에 넣는다.
  - (2) 사진 보정 작업(worker) 프로세스들은 이 작업을 메시지 큐에서 꺼내 비동기적으로 완료한다.

- 위처럼 하면 생산자와 소비자 서비스의 규모는 각기 독립적으로 확장될 수 있다. 큐의 크기가 커진다면 더 많은 작업 프로세스를  
  추가해야 처리 시간을 줄일 수 있다. 하지만 큐가 거의 항시 비어있는 상태라면, 작업 프로세스의 수를 줄일 수 있을 것이다.

<hr/>

## 로그, 메트릭, 자동화

- 로그(log), 메트릭(metric), 자동화(automation)은 규모가 커질 수록 필수적인 요소가 된다.

### 로그

- 에러 로그를 모니터링하는 것은 중요하다. 시스템의 오류와 문제들을 보다 쉽게 찾아낼 수 있게하기 때문이다.  
  에러 로그는 서버 단위로 모니터링할 수도 있지만, 로그를 단일 서비스로 모아주는 도구를 활용하면 더욱 편리하게  
  검색하고 조회할 수 있다.

### 메트릭

- 메트릭을 잘 수집하면 사업 현황에 관한 유용한 정보를 얻을 수도 있고, 시스템의 현재 상태를 손쉽게 파악할 수도 있다.  
  메트릭 가운데 특히 유용한 것들을 몇 가지 보자.

  - **호스트 단위 메트릭** : CPU, Memory, Disk I/O 에 대한 메트릭
  - **종합(aggregated) 메트릭** : 데이터베이스 계층의 성능, 캐시 계층의 성능 등
  - **핵심 비즈니스 메트릭** : 일별 능동 사용자(DAU), 수익(revenue), 재방문률(retention rate) 등

### 자동화

- 시스템이 크고 복잡해지면 생산성을 높이기 위해 자동화 도구를 활용해야 한다. 가령, CI를 도와주는 도구를 활용하면  
  개발자가 만드는 코드가 어떤 검증 절차를 자동으로 거치도록 할 수 있어 문제를 쉽게 감지할 수 있다.  
  이 외에도 빌드, 테스트, 배포 등의 절차를 자동화할 수 있어 개발 생산성을 크게 향상시킬 수 있다.

<hr/>

## 데이터베이스 규모 확장

- 저장할 데이터가 많아지면 데이터베이스에 대한 부하도 증가하기 마련이다. 이때가 온다면 데이터베이스를 증설할  
  방법을 찾아야 한다.

- 데이터베이스 규모 확장에는 서버의 규모 확장과 마찬가지로 수직적 규모 확장과 수평적 규모 확장법이 있다.

### 수직적 확장

- Scale Up이라고도 하는 수직적 확장은 기존 서버에 더 많은, 또는 고성능의 자원(CPU, Ram, Disk 등)을 증설하는 방법이다.  
  예를 들어, AWS RDS는 24TB RAM을 갖춘 서버도 제공하는데, 이 정도 수준의 고성능 데이터베이스 서버는 많은 양의 데이터를  
  보관하고 처리할 수 있다.

- 하지만 이러한 수직적 접근법에는 몇 가지 심각한 약점이 있다.

  - 데이터베이스 서버 하드웨어에는 한계가 있으므로 CPU, RAM 등을 무한 증설할 수 없다.  
    사용자가 계속 늘어난다면 한 대의 서버로는 결국 감당하기 어렵게 될 것이다.

  - SPOF로 인한 위험성이 크다.

  - 비용이 많이 든다. 고성능 서버로 갈수록 가격이 올라가기 마련이다.

### 수평적 확장

- 데이터베이스의 수평적 확장은 sharding이라고도 하는데, 더 많은 서버를 추가함으로써 성능을 향상시킬 수 있게끔 한다.

- sharding은 대규모 데이터베이스를 shard라 하는 작은 단위로 분할하는 기술을 일컫는다.  
  모든 shard는 같은 스키마를 사용하지만, 각 shard에 보관되는 데이터 사이에는 중복이 없다.

- 예를 들어, 정수형의 userId를 4로 나눈 나머지(`userId % 4`)를 해시 함수로 이용해 데이터가 보관될 shard를  
  정할 수 있다. 나머지가 0이면 0번 shard에, 1이면 1번 shard에 보관하는 방식이다.

- sharding 전략을 구현할 때 고려해야 할 가장 중요한 점은 **Sharding Key의 결정 방식** 이다.  
  Sharding Key는 Partitioning Key라고도 불리는데, 데이터가 어떻게 분산될지를 정하는 하나 이상의 컬럼으로 구성된다.  
  이전에 본 예시에서의 Shardking Key는 userId 이다. Sharding Key를 통해 올바른 데이터베이스에 질의를 보내  
  데이터 조회나 변경을 처리하기에 효율을 높일 수 있다. Sharding Key를 정할 때는 데이터를 고르게 분할할 수 있도록  
  하는 것이 가장 중요하다.

- Sharding은 데이터베이스 규모 확장을 실현하는 훌륭한 기술이지만, 완벽하지는 않다.  
   Sharding을 도입하면 시스템이 복잡해지고 풀어야 할 새로운 문제도 생긴다.

  - **데이터의 resharding** : Resharding은 아래와 같은 경우에 필요하다.

    - (1) 데이터가 너무 많아져 하나의 shard로는 더 이상 감당하기 어려울 때
    - (2) Shard 간의 데이터 분포가 균등하지 못해 어떤 shard에 할당된 공간 소모가 다른 shard에 비해  
      빠르게 진행될 때. 이는 shard exhaustion(shard 소진)이라고도 불리는 현상인데, 이런 현상이 발생하면  
      shard key를 계산하는 함수를 변경하고 데이터를 재배치해야 한다.

  - **유명인사(celebrity) 문제** : Hotspot Key라고도 불리는 이 문제는 특정 shard에 질의가 집중되어  
    서버에 과부하가 걸리는 문제다. 예를 들어, SNS의 유명인사가 모두 같은 shard에 저장되는 데이터베이스가 있다 하자.  
    이러한 애플리케이션은 특정 shard에 read 연산이 집중되어 과부하가 걸리게 될 것이다. 이 문제를 풀려면 유명인사  
    각각에 샤드 하나씩을 할당해야 할 수도 있고, 심지어는 더 잘게 쪼개야 할 수도 있다.

  - **Join과 De-Normalization** : 일단 하나의 데이터베이스를 여러 개의 shard로 쪼개고 나면, 여러 shard에 걸친  
    데이터를 join하기가 힘들어진다. 이를 해결하는 한 가지 방법은 데이터베이스를 비정규화해 하나의 테이블에서 질의가  
    수행될 수 있도록 하는 것이다.

<hr/>

## 정리

- 웹 계층은 무상태 계층으로 하자.

- 모든 계층에 다중화를 도입하자.

- 가능한 한 많은 데이터를 캐싱하자.

- 여러 데이터 센터를 지원하자.

- 정적 컨텐츠는 CDN을 통해 서비스하자.

- 데이터 계층은 sharding을 통해 그 규모를 확장시키자.

- 각 계층은 독립적인 서비스로 분할하자.

- 시스템을 지속적으로 모니터링하고, 자동화 도구들을 활용하자.

<hr/>
