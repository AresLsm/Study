# 테스트 해보기

## 테스트 컨테이너 사용 테스트

- 이제 테스트 컨테이너를 사용할 준비를 마쳤다.  
  이제 테스트 대상 시스템에 어떤 동작을 테스트할지 먼저 정해보자.  
  지금까지 비동기 메시징 솔루션에 대해 이야기했는데, 웹 컨트롤러에서  
  새로운 `Item`객체의 생성 요청을 받아 RabbitMQ를 통해 메시지로  
  전달하는 과정을 구현해보자. 메시지를 받아서 MongoDB에 저장하는  
  서비스도 함께 구현할 것이다.

- 메시지를 매개체로 사용하는 이 단순한 개념은 여러 방식으로 응용해서 얼마든지 재사용할 수 있다.  
  예를 들어, 웹 컨트롤러 대신 다른 것으로 대체할 수도 있다. 그렇게 해도 메시지는  
  RabbitMQ를 통해 전송된다. 또는 메시지를 전송하는 API를 직접 호출하게 할 수도 있다.

- 일단 처음에 시도하려 했던 것부터 해보자. 동기적인 웹 요청을 받아서 비동기 메시지로 바꾸는  
  웹 컨트롤러를 만들어보자. 이번에는 테스트를 먼저 작성하는 방식으로 진행해보자.

```kt
@SpringBootTest // (1)
@AutoConfigureWebTestClient // (2)
@Testcontainers // (3)
@ContextConfiguration // (4)
class RabbitMQTest {

    companion object {
        @Container
        val container = RabbitMQContainer("rabbitmq:3.7.25-management-alpine") // (5)

        @DynamicPropertySource // (6)
        fun configure(registry: DynamicPropertyRegistry) {
            registry.add("spring.rabbitmq.host", container::getContainerIpAddress)
            registry.add("spring.rabbitmq.port", container::getAmqpPort)
        }
    }

    @Autowired
    private lateinit var webTestClient: WebTestClient

    @Autowired
    private lateinit var repository: ItemRepository
}
```

- 위 코드에 대한 설명은 아래와 같다.

  - (1) `@SpringBootTest`는 자동설정, 환경설정 값 읽기, 내장 웹 컨테이너 등 테스트를 위한  
    애플리케이션 구동에 필요한 모든 것을 활성화한다. 기본적으로 실제 운영환경이 아니라 실제 운영환경을  
    mocking한 환경을 사용한다.

  - (2) `@AutoConfigureWebTestClient`를 적용해서 테스트용으로 사용하는 webClient인  
    `WebTestClient`를 자동설정한다.

  - (3) `@TestContainer`는 JUnit5에서 제공하는 어노테이션으로, 테스트컨테이너를 테스트에  
    사용할 수 있게 해준다.

  - (4) `@ContextConfiguration`은 지정한 클래스를 테스트 실행 전에 먼저 Application Context에  
    로딩해준다.

  - (5) 테스트에 사용할 `RabbitMQContainer`를 생성한다. `RabbitMQContainer`는 테스트에 사용할  
    RabbitMQ 인스턴스를 관리한다.

  - (6) `@DynamicPropertySource`는 Java8의 함수형 인터페이스인 `Supplier`를 사용해서  
    환경 설정 내용을 `Environment`에 동적으로 추가한다. `container::getContainerIpAddress`와  
    `container::getAmqpPort` 메소드 핸들을 사용해서 테스트컨테이너에서 실행한 RabbitMQ 브로커의  
    호스트명과 포트 번호를 가져온다. 이렇게 하면 RabbitMQ 연결 세부 정보를 테스트컨테이너에서 읽어와서  
    Spring AMQP에서 사용할 수 있도록 스프링 부트 환경설정 정보에 저장한다.

- 테스트를 작성하기 전에 먼저 알아야할 것이 있다. 지금까지 Project Reactor를 사용하는  
  테스트에서는 `StepVerifier`를 사용해서 비동기 처리 흐름을 쉽게 테스트할 수 있었고,  
  지연 효과를 흉내낼 수도 있었다. 하지만 RabbitMQ를 사용하는 테스트에서는 `RabbitVerifier`같은  
  것이 없어서 `Thread.sleep()`을 사용해야 한다.

- 그런데 이번에는 테스트를 작성하기 전에 어떤 스프링 프로젝트를 사용해야 되는지 아무런 언급이  
  없었다는 것이 이상하지 않은가? 왜냐하면 아직 테스트 대상조차 없는 상태에서 테스트를 먼저 작성하는  
  test-first 전략을 사용하기 때문이다.

<hr/>

## 테스트 케이스 구성

- 웹 컨트롤러의 초안을 만들기 전에, 웹 컨트롤러가 처리해야할 일을 먼저 나열해보자.

  - (1) 새 `Item` 객체를 생성하기 위해 `Item` 데이터가 담겨있는 HTTP POST 요청을 받는다.
  - (2) `Item` 데이터를 적절한 메시지로 변환한다.
  - (3) `Item` 생성 메시지를 브로커에게 전송한다.

- 메시지를 받는 역할을 하는 브로커가 해야할 일은 아래와 같다.

  - (1) 새 메시지를 받을 준비를 하고 기다린다.
  - (2) 새 메시지가 들어오면 꺼내서,
  - (3) MongoDB에 저장한다.

- 잊지말아야 할 것은 개발자가 직접 하든, 프레임워크에게 위임하든 **구독을 해야 동작**한다는 점이다.  
  이제 실제 테스트 케이스를 작성해보자. 물론 실제 테스트 대상이 구현되지 않은 상태이므로  
  당장은 실패한다.

```kt
@SpringBootTest
@AutoConfigureWebTestClient
@Testcontainers
@ContextConfiguration
class RabbitMQTest {

    // 설정들

    @Test
    @Throws(InterruptedException::class)
    fun verifyMessagingThroughAmqp() {
        webTestClient.post().uri("/items") // (1)
            .bodyValue(Item("Alf alarm clock", "nothing important", 19.99))
            .exchange()
            .expectStatus().isCreated
            .expectBody()

        Thread.sleep(1500L) // (2)

        webTestClient.post().uri("/items") // (3)
            .bodyValue(Item("Smurf TV tray", "nothing important", 29.99))
            .exchange()
            .expectStatus().isCreated
            .expectBody()

        Thread.sleep(2000L) // (4)

        repository.findAll() // (5)
            .`as`(StepVerifier::create)
            .expectNextMatches { item ->
                assertEquals("Alf alarm clock", item.name)
                assertEquals("nothing important", item.description)
                assertEquals(19.99, item.price)
                true
            }
            .expectNextMatches { item ->
                assertEquals("Smurf TV tray", item.name)
                assertEquals("nothing important", item.description)
                assertEquals(29.99, item.price)
                true
            }
            .verifyComplete()
    }
}
```

- 테스트 코드가 하는 일은 각각 아래와 같다.

  - (1) 새 `Item` 데이터를 `/items`에 POST로 요청한다. 요청에 대한 응답으로 HTTP_CREATED_201이  
    반환되는 것을 확인한다.

  - (2) 1500ms 동안 `sleep()` 처리해서 해당 메시지가 브로커를 거쳐 데이터 저장소에 저장될 때까지  
    기다린다. 이렇게 해서 테스트에 사용되는 메시지의 처리 순서를 맞출 수 있다.

  - (3) 두 번째 `Item` 데이터를 보내고, HTTP_CREATED_201이 반환되는 것을 확인한다.

  - (4) 두 번째 메시지가 처리될 수 있도록 2000ms 동안 `sleep()` 한다.

  - (5) `ItemRepository`를 사용해서 MongoDB에 쿼리를 날려서 2개의 `Item`객체가 저장된 것을 확인한다.

- 먼저 알아둘 것은 이 테스트가 **실제 RabbitMQ 브로커를 대상으로 수행된다**는 점이다.  
  아직 `Item` 데이터를 받아서 메시지로 변환하고 브로커에 보내서 MongoDB에 저장하는 로직이  
  구현돼있지 않으므로 테스트를 실행하면 물론 실패한다. 이제부터 이 로직을 구현해서 테스트를  
  통과시켜보자.

- 앞서 스프링의 역사를 살펴볼 때, 스프링은 Java의 복잡도를 낮추는 것을 목표로 한다고 했다.  
  Spring AMQP는 널리 사용되는 메시징 프로토콜인 AMQP를 스프링 방식으로 사용할 수 있게 해준다.

```gradle
//..

dependencies{

    //..
    implementation("org.springframework.boot:spring-boot-starter-amqp")
}
```

- 위 의존성을 추가하고, 이제 POST 요청을 리액티브 방식으로 처리할 수 있는 Spring Webflux  
  REST 컨트롤러를 작성해보자.

```kt
package com.sangwoo.commerce.controller

import com.sangwoo.commerce.domain.Item
import org.slf4j.Logger
import org.slf4j.LoggerFactory
import org.springframework.amqp.core.AmqpTemplate
import org.springframework.http.ResponseEntity
import org.springframework.web.bind.annotation.PostMapping
import org.springframework.web.bind.annotation.RequestBody
import org.springframework.web.bind.annotation.RestController
import reactor.core.publisher.Mono
import reactor.core.scheduler.Schedulers
import java.net.URI

@RestController
class SpringAmqpItemController(private val template: AmqpTemplate) { // (1)

    companion object {
        private val log: Logger = LoggerFactory.getLogger(SpringAmqpItemController::class.java)
    }

    @PostMapping("/items")
    fun addNewItemUsingSpringAmqp(@RequestBody item: Mono<Item>): Mono<ResponseEntity<*>> {
        return item
            .subscribeOn(Schedulers.boundedElastic()) // (2)
            .flatMap { content ->
                Mono.fromCallable { // (3)
                    template.convertAndSend("SpringWebflux", "new-items-spring-amqp", content) // (4)
                    ResponseEntity.created(URI.create("/items")).build<Void>() // (5)
                }
            }
    }
}
```

- 위 코드에 대한 설명은 아래와 같다.

  - (1) `spring-boot-starter-amqp`는 Spring AMQP를 classpath에 추가한다. 그래서  
    Spring Boot 자동설정을 통해 `AmqpTemplate`을 테스트에 사용할 수 있다. RabbitMQ를  
    사용하므로 실제 구현체로는 `RabbitTemplate`이 사용된다. 생성자를 통해 `AmqpTemplate`을  
    주입받아서 메시지를 전송할 때 사용한다.

  - (2) `AmqpTemplate`은 블로킹 API를 호출하므로 `subscribeOn()`을 통해  
    **Bounded Elastic Scheduler**에서 관리하는 별도의 스레드에서 실행되게 만든다.

  - (3) 람다식을 사용해서 `AmqpTemplate`의 호출을 `Callable`로 감싸고, `Mono.fromCallable()`을  
    사용해 `Mono`를 생성한다.

  - (4) `AmqpTemplate`의 `convertAndSend()`를 호출하여 `Item` 데이터를  
    new-items-spring-amqp라는 Routing Key와 함께 SpringWebflux exchange로 전송한다.

  - (5) 새로 생성되어 추가된 `Item` 객체에 대한 URI를 location 헤더에 담아 HTTP_201_CREATED  
    상태코드와 함께 반환한다.

- RabbitMQ는 블로킹 API를 호출한다. RabbitMQ는 비동기 메시징 시스템이긴 하지만, 많은  
  RabbitMQ API는 작업 수행 중 현재 스레드를 블록한다. 이 미묘한 차이를 이해하는 것이 중요하다.  
  결국에는 비동기 처리 과정으로 되돌아가더라도 어떤 API가 현재 스레드를 블로킹한다면 블로킹 API다.

- 위 예제 코드에서는 긴 시간동안 블로킹하지 않으므로 큰 문제가 되지 않을 것 같지만,  
  이런 블로킹에 의해 발생하는 지연이 쌓이고 쌓이면, 나중에 무시하지 못할 부담이 될 수 있다.  
  그래서 Project Reactor에서는 이 문제를 해결할 방법을 만들어뒀다.

<hr/>

## 스케줄러를 사용해서 블로킹 API 감싸기

- 리액터는 스레드에 대해 알지 못한다. 리액터의 API를 사용할 때 멀티스레드 프로그래밍을  
  반드시 활용해야 하는 것은 아니다. 수십 개에서 수백 개의 스레드를 사용하는 것은  
  여러 문제를 일으키며, 그다지 좋은 방법이라고 할 수 없다.

- 리액터를 사용할 때는 AMQP의 예제에서 본 것처럼 여러 단계(step)의 작업 절차를  
  만들게 된다. 리액터는 스케줄러(Scheduler)를 통해 개별 수행 단계가 어느 스레드에서  
  실행될지 지정할 수 있다.

- 한 개의 스레드만을 사용하면서도 비동기 논블로킹 코드를 작성할 수 있다.  
  한 개의 스레드가 작업을 수행할 수 있을 때, 다시 말하면 스레드가 시스템 자원의  
  가용성에 _반응_ 할 준비가 돼 있을 때, 개별 수행 단계를 실행하는 방식을  
  사용하면 가능하다. 하나의 작업 단계가 완료되면 스레드는 리액터의 작업 코디네이터에게  
  반환되고, 다음에 어떤 작업을 실행할지 결정된다. 모든 작업이 이처럼 개별 단계가  
  완료될 때마다 스케줄러에게 스레드를 반환하는 패러다임으로 수행될 수 있다면,  
  스레드의 숫자는 전통적인 **멀티스레드 프로그래밍**에서만큼 중요하지는 않게 된다.

- 작업 수행 단계 도중에 블로킹 API 호출이 포함된다면, 리액터에게 알려서 블로킹 API를  
  별도의 스레드에서 호출하게 해야 의도하지 않은 스레드 낭비를 방지할 수 있다.  
  리액터는 아래와 같이 여러 방법으로 스레드를 사용할 수 있다.

  - `Schedulers.immediate()`: 현재 스레드
  - `Schedulers.single()`: 재사용 가능한 하나의 스레드. 현재 수행중인 리액터  
    플로우 뿐만 아니라 호출되는 모든 작업이 동일한 하나의 스레드에서 실행된다.
  - `Schedulers.newSingle()`: 새로 생성한 전용 스레드
  - `Schedulers.boundedElastic()`: 작업량에 따라 스레드 숫자가 늘어나거나  
    줄어드는 신축성 있는 스레드풀
  - `Schedulers.parallel()`: 병렬 작업에 적합하도록 최적화된 고정 크기의  
    worker 스레드풀
  - `Schedulers.fromExecutorService()`: `ExecutorService`를 감싸서 재사용

> `single()`, `newSingle()`, `parallel()`은 논블로킹 작업에 사용되는 스레드를 생성한다.  
> 이 세가지 스케줄러에 의해 생성되는 스레드는 리액터의 `NonBlocking` 인터페이스를 구현한다.  
> 따라서 `block()`, `blockFirst()`, `blockLast()` 같은 블로킹 코드가 사용되면  
> `IllegalStateException`이 발생한다.

- 리액터 플로우에서 스케줄러를 변경하는 방법은 두 가지다.

  - `publishOn()`: 호출되는 시점 이후로는 지정한 스케줄러를 사용한다. 이 방법을 사용하면  
    사용되는 스케줄러를 여러 번 바꿀 수도 있다.
  - `subscribeOn()`: 플로우 전 단계에 걸쳐 사용되는 스케줄러를 지정한다. 플로우 전체에  
    영향을 미치므로 `publishOn()`에 비해 영향 범위가 더 넓다.

- `addNewItemUsingSpringAmqp()` 메소드 내에서 `subscribeOn(Schedulers.boundedElastic())`이  
  호출되고 있다. 이렇게 하면 블로킹 호출을 처리할 수 있는 신축성 있는 스레드 풀을 사용할 수 있다.  
  이 신축성 스레드 풀은 별도의 스레드 풀이므로 블로킹 API 호출이 있더라도, 다른 리액터 플로우에  
  블로킹 영향을 전파하지 않는다. 앞서 설명한 것처럼 `subscribeOn()`을 호출하는 위치는 중요하지 않다.  
  리액터 플로우에서 `subscribeOn()`이 어디에 위치하든 해당 플로우 전체가 `subscribeOn()`으로  
  지정한 스레드에서 실행된다. 다만 나중에 `publishOn()`으로 스레드를 다시 지정하면, 지정한 지점  
  이후부터는 `publishOn()`으로 새로 지정한 스레드에서 리액터 플로우가 실행된다.

<hr/>

## Consumer 작성

- Webflux 컨트롤러에 메시지 producer가 단정하게 작성되어 있으므로, 이제  
  RabbitMQ consumer를 만들어야 한다. Spring AMQP에는 consumer를 만들 수 있는  
  여러 방법들이 준비되어 있다. 가장 단순한 방식은 `AmqpTemplate.receive(queueName)`이지만,  
  이는 가장 좋은 방식이라고 할 수는 없다. 특히 부하가 많은 상황에서는 적합하지 않다.  
  더 많은 메시지를 polling 방식으로 처리할 수도 잇고, callback을 등록해서 처리할 수도 있지만,  
  `@RabbitListener`를 사용하는 것이 가장 유연하고 편리하다.

```kt
@Service
class SpringAmqpItemService(private val repository: ItemRepository) {

    companion object {
        private val log = LoggerFactory.getLogger(SpringAmqpItemService::class.java)
    }

    @RabbitListener( // (1)
        ackMode = "MANUAL",
        bindings = [
            QueueBinding( // (2)
                value = Queue(), // (3)
                exchange = Exchange("SpringWebflux"),  // (4)
                key = ["new-items-spring-amqp"] // (5)
            )
        ]
    )
    fun processNewItemsViaSpringAmqp(item: Item): Mono<Void> {  // (6)
        log.debug("Consuming => $item")
        return repository.save(item).then() // (7)
    }

```

- 위 코드의 설명은 아래와 같다.

  - (1) `@RabbitListener`가 붙은 메소드는 Spring AMQP 리스너로 등록되어  
    메시지를 소비할 수 있다.

  - (2) `@QueueBinding`은 큐를 exchange에 바인딩하는 방법을 지정한다.

  - (3) `@Queue`는 임의의 지속성 없는 익명 큐를 생성한다. 특정 큐를 지정하려면,  
    `@Queue(name = "")`를 사용해 이름을 지정한다. durable, exclusive, autoDelete같은  
    속성값도 지정할 수 있다.

  - (4) `@Exchange`는 이 큐와 연결될 exchange를 지정한다. 예제에서는 "SpringWebflux" exchange를  
    큐와 연결한다. exchange의 다른 속성값을 설정할 수도 있다.

  - (5) key 속성은 Routing Key를 지정한다.

  - (6) `@RabbitListener`에서 지정한 내용에 맞는 메시지가 들어오면  
    `processNewItemsViaSpringAmqp()`가 실행되며, 메시지에 들어 있는 `Item` 데이터는 item 매개변수를  
    통해 전달된다.

  - (7) `Item` 객체가 MongoDB에 저장된다. 반환 타입이 Reactor 타입인 `Mono`이므로 `then()`을  
    호출하여 저장이 완료될 때까지 기다린다. Spring AMQP는 리액터 타입도 처리할 수 있으므로 구독도  
    Spring AMQP에게 위임할 수 있다.

- 메소드 내용은 간단하지만, Spring AMQP 사용을 위한 어노테이션에 대해 알아볼 점들이 많다.

- Spring AMQP는 비동기 메시지를 여러 가지 방법으로 소비할 수 있다.  
  `@RabbitListener`를 사용하는 방법이 가장 직관적이다. 이름 있는 큐를 사용할 수도 있고,  
  위 예제처럼 익명 큐를 사용할 수도 있다.

> **익명 큐(Anonymous Queue)** 와 **이름 있는 큐(Named Queue)** 는 무슨 차이가 있을까?  
> 동일한 메시지를 여러 consumer가 사용해야 하는 상황에서는 용도에 맞게 설정하는 것이 중요하다.  
> 만약 2개의 consumer가 동일한 큐를 사용하도록 설정되면, 하나의 메시지는 두 consumer 중  
> 하나의 consumer만 접근해서 사용할 수 있다. 다시말해, 하나의 큐에 있는 메시지는 단 하나의  
> 클라이언트에 의해서만 소비될 수 있다. 동일한 routing key를 사용하는 하나의 exchange에  
> 2개의 consumer가 연결되어 있지만, 각각 다른 큐를 사용한다면, 하나의 메시지가 다른 큐에  
> 복제되므로 메시지 발행자 쪽을 변경하지 않고도 두 개의 consumer가 모두 해당 메시지를 사용할 수 있다.

- `@RabbitListener` 어노테이션을 메소드에 붙이면, Spring AMQP가 가능한 한 가장  
  효율적인 캐시 및 polling 메커니즘을 적용하고 백그라운드에서 리스너를 등록한다.

- Spring AMQP를 사용하면 Java의 `Serializable` 인터페이스를 사용해서 직렬화 처리를 할 수 있다.  
  지금까지 작성한 메시지를 `Serializable`을 구현하도록 변경하면 그리 어렵지 않게  
  직렬화할 수 있지만, 최선의 방법이라고 할 수는 없다.

> `Serializable`을 피하는 것이 얼마나 중요할까? 역직렬화가 Java에 포함되어 있는 여러 보안 검사를  
> 우회한다는 것은 널리 알려져 있다. 그래서 예전부터 다양한 보안 공격에 활용돼 왔고, Java 개발 진영에게는  
> 필요악과도 같은 존재다. `Serializable`을 사용하는 것보다는 Jackson같은 라이브러리를 사용해서  
> 더 엄격하게 제어하는 것이 더 낫다. 그래서 Jackson을 사용해서 성능 저하가 발생한다는 확실한  
> 벤치마크 결과가 나오지 않는 한, 일반적으로 저자는 `Serializable` 대신 Jackson의 사용을 권장한다.

- 다른 대안으로는 POJO 객체를 JSON 같은 문자열로 변환하고, 문자열을 byte 배열로 만들어서  
  네트워크를 통해 전송하는 방법이 있다. Spring에서 JSON 직렬화를 담당하는 Jackson 라이브러리를  
  사용하는 방법은 매우 간단하다. 아래와 같이 Spring Bean을 하나 등록하면 된다.

```kt
@SpringBootApplication
@EnableHypermediaSupport(type = [HypermediaType.HAL_FORMS])
class Application {
    @Bean
    fun jackson2JsonMessageConverter(): Jackson2JsonMessageConverter {
        return Jackson2JsonMessageConverter()
    }
}
```

- 이렇게 `Jackson2JsonMessageConverter`를 Spring Bean으로 등록하면 Spring Framework의  
  `MessageConverter`가 자동으로 활성화된다. `MessageConverter`는 POJO 객체를 JSON으로  
  전환하거나, JSON을 POJO 객체로 전환하는 역할을 담당한다.

- 리스너도 등록했고, 직렬화 라이브러리 사용 준비도 마쳤으므로, 이제 테스트를 실행해보자.

<hr/>
