# 검색어 자동완성 시스템 설계

- 이번에는 입력 중인 글자에 맞는 검색어를 자동으로 완성시켜 표시해주는 검색어 자동완성 시스템을 설계해보자.

## 문제 이해 및 설계 범위 확정

- 아래는 이번에 설계할 검색어 자동완성 시스템의 요구 사항이다.

  - 빠른 응답 속도: 사용자가 검색어를 입력함에 따라 자동완성 검색어도 충분히 빨리 표시되어야 한다. Facebook 검색어 자동완성 시스템의 경우,  
    시스템 응답속도는 100ms 이내이다. 그렇지 않으면 시스템 이용이 불편해진다.

  - 연관성: 자동완성되어 출력되는 검색어들은 사용자가 입력한 단어와 연관된 것이어야 한다.

  - 정렬: 시스템의 계산 결과는 popularity(인기도) 등의 ranking model(순위 모델)에 의해 정렬되어 있어야 한다.

  - 규모 확장성: 시스템은 많은 트래픽을 감당할 수 있도록 확장 가능해야 한다.

  - 고가용성: 시스템의 일부에 장애가 발생하거나, 느려지거나, 예상치 못한 네트워크 문제가 생겨도 시스템은 계속 사용 가능해야 한다.

### 개략적 규모 추정

- DAU는 1000만 명으로 간주한다.
- 평균적으로 한 사용자는 매일 10건의 검색을 수행한다.
- 질의할 때마다 평균적으로 20byte의 데이터를 입력한다고 가정한다.
  - 문자 encoding 방법으로는 ASCII를 사용한다. 따라서 `1문자 = 1byte` 이다.
  - 질의문은 평균적으로 4개 단어로 이뤄진다고 가정할 것이며, 각 단어는 평균적으로 5개 글자로 구성된다고 가정할 것이다.
  - 따라서 질의당 평균 `4 * 5 = 20` byte이다.
- 검색창에 글자를 입력할 때마다 클라이언트는 검색어 자동완성 백엔드에 요청을 보낸다. 따라서 평균적으로 1회 검색당 20건의 요청이 발생한다.  
  예를 들어 dinner라고 입력한다면, 아래의 6개 요청이 순차적으로 발생한다.
  - `search?q=d`
  - `search?q=di`
  - `search?q=din`
  - `search?q=dinn`
  - `search?q=dinne`
  - `search?q=dinner`
- 대략 초당 24,000건의 질의(QPS)가 발생할 것이다.
- 최대 QPS는 `QPS * 2 = 대략 48,000` 이다.
- 질의 가운데 20% 정도는 신규 검색어라고 가정한다.  
  따라서 대략 0.4GB 정도이며, 이는 곧 매일 0.4GB의 신규 데이터가 시스템에 추가된다는 뜻이다.

---

## 개략적 설계안 제시 및 동의 구하기

- 개략적으로 보면 시스템은 크게 두 부분으로 나뉜다.

- 데이터 수집 서비스(Data gathering service): 사용자가 입력한 질의를 실시간으로 수집하는 시스템이다. 데이터가 많은 애플리케이션에  
  실시간 시스템은 그다지 바람직하지 않지만, 설계안을 만드는 출발점으로는 괜찮을 것이다.

- 질의 서비스(Query service): 주어진 질의에 다섯 개의 인기 검색어를 정렬해 내놓는 서비스이다.

### Data gathering service

- 데이터 수집 서비스가 어떻게 동작하는지 간단한 예제를 통해 살펴보자. Query문과 사용 빈도를 저장하는 Frequency table(빈도 테이블)이 있다고 해보자.

![picture 1](/images/SDI_SKAS_1.png)

- 이 테이블은 처음에 비어있는데, 사용자가 "twitch", "twitter", "twitter", "twillo"를 순서대로 검색하면 그 상태가 위처럼 바뀌어 나가게 된다.

### Query service

- 아래 표와 같은 빈도 테이블이 있는 상태라고 해보자. 2개의 필드가 있음을 확인할 수 있다.

| query          | frequency |
| -------------- | --------- |
| twitter        | 35        |
| twitch         | 29        |
| twilight       | 25        |
| twin peak      | 21        |
| twitch prime   | 18        |
| twitter search | 10        |
| twin peack sf  | 8         |

- 이 상태에서 사용자가 "tw"를 검색창에 입력하면, 아래의 "top 5" 자동완성 검색어가 표시되어야 한다.  
  "top 5"는 위의 빈도 테이블에 기록된 수치를 사용해 계산한다고 가정한다.

![picture 2](/images/SDI_SKAS_2.png)

- 가장 많이 사용된 5개 검색어는 아래의 SQL문을 통해 계산할 수 있다.

```sql
SELECT * FROM frequency_table
WHERE query LIKE 'prefix%'
ORDER BY frequency DESC
LIMIT 5;
```

- 이와 같은 접근법은 데이터 양이 적을 때는 나쁘지 않다. 하지만 데이터가 아주 많아지면 데이터베이스가 병목이 될 수 있다.  
  상세 설계안을 준비하면서 이 문제를 해결할 방법을 알아보자.

---

## 상세 설계

- 데이터 수집 서비스와 질의 서비스의 두 부분으로 구성된 개략적 설계안은 최적화된 결과물이라 말하긴 어렵지만, 출발점으로는 썩 괜찮다.  
  이번에는 컴포넌트를 몇 개 골라 보다 상세히 설계하고 다음 순서로 최적화 방안을 논의해보자.

  - Trie 자료구조
  - 데이터 수집 서비스
  - 질의 서비스
  - 규모 확장이 가능한 저장소
  - Trie 연산

### Trie Data Structure

- 개략적 설계안에서는 RDBMS를 저장소로 사용했었다. 하지만 RDBMS를 사용해 가장 인기 있는 5개의 질의문을 골라내는 방안은 효율적이지 않다.  
  이 문제는 trie를 사용해 해결할 것이다. Trie가 시스템의 핵심적 부분이 될 것이므로, 충분한 시간을 할애해 주어진 요구사항에 딱 맞는  
  trie를 만들도록 할 것이다.

- 이번 장에서는 trie가 무엇인지 간단하게만 살펴보고, 이 기본 trie를 어떻게 최적화하면 응답 시간을 줄일 수 있는지에 집중해보자.

- Trie는 문자열들을 간략하게 저장할 수 있는 자료구조다. Trie라는 이름은 "retrieval"라는 단어에서 온 것인데, 문자열을 꺼내는 연산에  
  초점을 맞춰 설계된 자료구조임을 미뤄 짐작할 수 있다. Trie 자료구조의 핵심 아이디어는 아래와 같다.

  - Trie는 tree 형태의 자료구조다.
  - 이 tree의 root node는 빈 문자열을 나타낸다.
  - 각 node는 character(글자) 하나를 저장하며, 26개(해당 글자 다음에 등장할 수 있는 모든 글자의 개수)의 child node를 가질 수 있다.
  - 각 tree node는 하나의 단어 또는 prefix string(접두어 문자열)을 나타낸다.

- 아래 그림은 질의어 'tree', 'try', 'true', 'toy', 'wish', 'win'이 보관된 trie이다.  
  해당 질의어를 나타내는 node는 굵은 외곽선으로 표시했다.

![picture 3](/images/SDI_SKAS_3.png)

- 기본 trie 자료구조는 node에 문자들을 저장한다. 이용 빈도에 따라 정렬된 결과를 내놓기 위해서는 node에 빈도 정보까지 저장할 필요가 있다.  
  가령, 아래와 같은 빈도 테이블이 있다고 해보자.

| query | frequency |
| :---: | :-------: |
| tree  |    10     |
|  try  |    29     |
| true  |    35     |
|  toy  |    14     |
| wish  |    25     |
|  win  |    50     |

### Data gathering service

- 이 빈도 정보를 trie node에 저장하게 되면 아래와 같은 상태가 될 것이다.

![picture 4](/images/SDI_SKAS_4.png)

- 그렇다면 이 trie로 검색어 자동완성은 어떻게 구현할 수 있을까?  
  알고리즘을 살펴보기 전에, 우선 용어 몇 가지를 정의하고 넘어가자.

  - `p`: prefix의 길이
  - `n`: trie 안에 있는 node들의 개수
  - `c`: 주어진 node의 child node 개수

- 가장 많이 사용된 질의어 `k`개는 아래와 같이 찾을 수 있다.

  - 해당 접두어를 표현하는 node를 찾는다. 시잔 복잡도는 `O(p)`이다.
  - 해당 node부터 시작하는 하위 tree를 탐색해 모든 유효 node를 찾는다.  
    유효한 검색 문자열을 구성하는 node가 유효 node이다. 시간 복잡도는 `O(c)`이다.
  - 유효 node들을 정렬해 가장 인기 있는 검색어 `k`개를 찾는다. 시간 복잡도는 `O(clogc)`이다.

![picture 5](/images/SDI_SKAS_5.png)

- 위 그림의 예제를 보자. `k = 2`이고 사용자가 검색창에 'be'를 입력했다고 하자.  
  알고리즘은 아래처럼 동작할 것이다.

  - (1) 접두어 node 'be'를 찾는다.
  - (2) 해당 node부터 시작하는 하위 tree를 탐색해 모든 유효 node를 찾는다.  
    이 그림의 경우 `[beer: 10], [best: 35], [bet: 29]`가 유효 node이다.
  - (3) 유효 node를 정렬해 2개만 골라낸다. `[best: 35]`와 `[bet: 29]`가 접두어 'be'에 대해 검색된 2개의 인기 검색어다.

- 이 알고리즘의 시간 복잡도는 위의 각 단계에 소요된 시간의 합, 즉 `O(p) + O(c) + O(clogc)`이다.

- 이 알고리즘은 직관적이긴 하지만 최악의 경우에는 `k`개의 결과를 얻기 위해 전체 trie를 다 검색해야 하는 일이 발생할 수 있다.  
  이 문제를 해결할 수 있는 방법으로는 아래의 두 가지가 있다.

  - 접두어의 최대 길이 제한
  - 각 node에 인기 검색어를 cache

#### 접두어의 최대 길이 제한

- 사용자가 검색창에 긴 검색어를 입력하는 일은 거의 없다. 따라서 `p` 값은 작은 정수값(가량 50) 이라 가정해도 안전하다.  
  검색어의 최대 길이를 제한할 수 있다면 _"접두어 node를 찾는"_ 단계의 시간 복잡도는 `O(p)`에서 `O(작은 상수값) = O(1)`로 바뀔 것이다.

#### Node에 인기 검색어 cache

- 각 node에 `k`개의 인기 검색어를 저장해두면 전체 trie를 검색하는 일을 방지할 수 있다. 5-10개 정도의 자동완성 제안을 표시하면 충분하므로,  
  `k`는 작은 값이다. 이 예시에서는 5개의 질의를 caching한다고 해보자.

- 각 node에 이렇게 인기 질의어를 caching하면 top 5 검색어를 질의하는 시간 복잡도를 엄청나게 낮출 수 있다. 하지만 각 node에 질의어를  
  저장할 공간이 많이 필요하게 된다는 단점도 있다. 그러나 빠른 응답속도가 아주 중요할 때는 이 정도 저장공간을 희생할 만한 가치는 있다.

- 아래 그림은 개선된 trie 구조다. 각 node에 가장 인기 있는 검색어 5개를 저장하도록 했다. 예를 들어 접두어 be를 나타내는 node에는  
  `[best: 35, bet: 29, bee: 15, beer: 10]` 5개의 검색어를 caching해두었다.

![picture 6](/images/SDI_SKAS_6.png)

- 위의 두 가지 최적화 기법을 적용하면 시간 복잡도가 어떻게 달라지는지 보자.

  - (1) 접두어 node를 찾는 시간 복잡도가 `O(1)`로 바뀐다.
  - (2) 최고 인기 검색어 5개를 찾는 질의 시간의 복잡도도 `O(1)`로 바뀐다. 검색 결과가 이미 caching되어 있기 때문이다.

- 각 단계의 시간 복잡도가 `O(1)`로 바뀐 덕분에 최고 인기 검색어 `k`개를 찾는 전체 알고리즘의 복잡도도 `O(1)`로 바뀌게 된다.

### Data gathering service

- 지금까지 살펴본 설계안은 사용자가 검색창에 뭔가 타이핑을 할 때마다 실시간으로 데이터를 수정한다.  
  이 방법은 아래의 두 가지 문제로 그다지 실용적이지 못하다.

  - 매일 수천만 건의 질의가 입력될 텐데, 그때마다 trie를 갱신하면 질의 서비스는 심각하게 느려질 것이다.
  - 일단 trie가 만들어지고 나면 인기 검색어는 그다지 자주 바뀌지 않을 것이다.  
    그러니 trie는 그렇게 자주 갱신할 필요가 없다.

- 규모 확장이 쉬운 데이터 수집 서비스를 만들려면 데이터가 어디서 오고 어떻게 이용되는지를 살펴야 한다. Twitter 같은 실시간 애플리케이션이라면  
  제안되는 검색어를 항상 신선하게 유지할 필요가 있을 수 있겠지만, google 검색 같은 애플리케이션이라면 그렇게 자주 바꿔줄 이유는 없을 것이다.

- 용례가 달라지더라도 데이터 수집 서비스의 토대는 바뀌지 않을 것이다. Trie를 만드는 데 쓰는 데이터는 보통 데이터 분석 서비스(analytics)나  
  logging service로부터 올 것이기 때문이다.

- 아래 그림은 데이터 분석 서비스의 수정된 설계안이다.

![picture 7](/images/SDI_SKAS_7.png)

- 이제 각 컴포넌트들을 차례로 살펴보자.

#### 데이터 분석 서비스 로그

- 데이터 분석 서비스 로그에는 검색창에 입력된 질의에 관한 원본 데이터가 보관된다. 새로운 데이터가 추가될 뿐, 수정은 이뤄지지 않으며  
  로그 데이터에는 index를 걸지 않는다.

| query |        time         |
| :---: | :-----------------: |
| tree  | 2019-01-01 22:01:01 |
|  try  | 2019-01-01 22:01:05 |
| tree  | 2019-01-01 22:01:10 |
|  toy  | 2019-01-01 22:01:11 |
| tree  | 2019-01-01 22:01:12 |
|  try  | 2019-01-03 22:03:03 |

#### 로그 취합 서버

- 데이터 분석 서비스로부터 나오는 로그는 보통 그 양이 엄청나고 데이터 형식도 제각각인 경우가 많다. 따라서 이 데이터를 잘 aggregate(취합) 해서  
  시스템이 쉽게 소비할 수 있도록 해야 한다.

- 데이터 취합 방식은 서비스의 용례에 따라 달라질 수 있다. 예를 들어 twitter와 같은 실시간 애플리케이션의 경우, 결과를 빨리 보여주는 것이 중요하므로  
  데이터 취합 주기를 보다 짧게 가져갈 필요가 있을 수 있다. 한편, 대부분의 경우에는 일주일에 한 번 정도로 로그를 취합해도 충분할 것이다.  
  따라서 가장 중요한 것은 데이터 취합의 실시간성이 얼마나 중요한가 이다.

#### 취합된 데이터

- 아래 표는 매주 취합한 데이터의 사례다. time 필드는 해당 주가 시작한 날짜를 나타낸다. frequency 필드는 해당 질의가 해당 주에 사용된 횟수의 합이다.

| query |    time    | frequency |
| :---: | :--------: | :-------: |
| tree  | 2019-10-01 |   12000   |
| tree  | 2019-10-08 |   15000   |
| tree  | 2019-10-15 |   9000    |
|  toy  | 2019-10-01 |   8500    |
|  toy  | 2019-10-08 |   6256    |
|  toy  | 2019-10-15 |   8866    |

#### 작업 서버

- 작업 서버(worker)는 주기적으로 비동기적 작업(job)을 실행하는 서버 집합이다.  
  Trie 자료구조를 만들고 Trie database에 저장하는 역할을 담당한다.

#### Trie cache

- Trie cache는 분산 cache 시스템으로 trie 데이터를 메모리에 유지해 읽기 연산의 성능을 높이는 구실을 한다. 매주 trie database의  
  snapshot을 떠서 갱신한다.

#### Trie database

- Trie database는 지속성 저장소다. Trie database로 사용할 수 있는 선택지로는 다음 두 가지가 있다.

  - Document Store: 새로운 trie를 매주 만들 것이므로, 주기적으로 trie를 직렬화해 데이터베이스에 저장할 수 있다.  
    MongoDB 같은 document store를 활용하면 이런 데이터를 편리하게 저장할 수 있다.

  - Key-value store: Trie는 아래 로직을 적용하면 hash table로 변환이 가능하다.

    - Trie에 보관된 모든 접두어를 hash table의 key로 변환
    - 각 trie node에 보관된 모든 데이터를 hash table의 value로 변환

- 아래 그림은 trie를 hash table로 어떻게 대응시킬 수 있는지 보여준다.

![picture 8](/images/SDI_SKAS_8.png)

- 각 trie node는 하나의 `<key, value>` pair로 변환된다.

### Query service

- 개략적 설계안에서 살펴본 질의 서비스는 데이터베이스를 활용해 top 5 검색어를 골라냈다.  
  아래는 해당 설계안의 비효율성을 개선한 설계안이다.

![picture 9](/images/SDI_SKAS_9.png)

- (1) 검색 질의가 load balancer로 전송된다.
- (2) Load balancer는 해당 질의를 API Server로 보낸다.
- (3) API Server는 Trie cache에서 데이터를 가져와 해당 요청에 대한 자동완성 검색어 제안 응답을 구성한다.
- (4) 데이터가 Trie cache에 없는 경우에는 데이터를 데이터베이스에서 가져와 cache에 채운다.  
  그래야 다음에 같은 접두어에 대한 질의가 오면 cache에서 보관된 데이터를 사용해 처리할 수 있다. Cache miss는 cache server의  
  메모리가 부족하거나 cache server에 장애가 있어도 발생할 수 있다.

- 질의 서비스는 정말 빨라야 한다. 이를 위해 아래와 같은 최적화 방안도 생각해보자.

  - AJAX Request: 웹 애플리케이션의 경우 브라우저는 보통 AJAX 요청을 보내 자동완성된 검색어 목록을 가져온다. 이 방법의 장점은  
    요청을 보내고 받기 위해 페이지를 새로고침할 필요가 없다는 것이다.

  - Browser caching: 대부분의 애플리케이션의 경우, 자동완성 검색어 제안 결과는 짧은 시간 안에 자주 바뀌지 않는다.  
    따라서 제안된 검색어들을 browser cache에 넣어두면 후속 질의의 결과는 해당 cache에서 바로 가져갈 수 있다.  
    Google 검색 엔진이 이런 cache mechanism을 사용한다. Google에 검색어를 입력해 검색하면, response header 중  
    `cache-control` header의 value에 등장하는 private는 해당 응답이 요청을 보낸 사용자의 cache에만 보관될 수 있으며  
    공용 cache에 저장되어서는 안 된다는 뜻이다. (`max-age=3600`은 해당 cache 항목이 3600초, 즉 1시간 동안만 유효하다는 뜻이다.)

  - Data sampling: 대규모 시스템의 경우, 모든 질의 결과를 logging 해놓으면 CPU 자원과 저장 공간을 엄청나게 소진하게 된다.  
    데이터 샘플링 기법은 그럴 때 유용하다. 즉 N개 요청 가운데 1개만 logging하도록 하는 것이다.

### Trie 연산

- Trie는 검색어 자동완성 시스템의 핵심 컴포넌트이다. 지금부터 trie 관련 연산들이 어떻게 동작하는지 살펴보자.

#### Trie 생성

- Trie 생성은 작업 서버가 담당하며, 데이터 분석 서비스의 로그나 데이터베이스로부터 취합된 데이터를 이용한다.

#### Trie 갱신

- Trie를 갱신하는 데는 두 가지 방법이 있다.

  - (1) 매주 1번 갱신하는 방법. 새로운 trie를 만든 후 기존 trie를 대체한다.
  - (2) Trie의 각 node를 개별적으로 갱신하는 방법. 이 설계안에서는 이 방법이 성능이 좋지 않기에 선택하지 않았다. 하지만 trie가 작을 때는  
    고려해볼 만한 방안이다. Trie node를 갱신할 때는 그 모든 상위 node도 갱신해야 하는데, 상위 node에도 인기 검색어 질의 결과가 보관되기 때문이다.  
    아래 그림은 이 갱신 연산이 어떻게 동작하는지 보여준다. Trie의 상태가 왼쪽 그림이라 해보자. 그리고 검색어 'beer'의 이용 빈도를 10에서 30으로  
    갱신해야 한다 해보자. 그러면 해당 node에 기록된 'beer' 이용 빈도는 오른쪽 그림과 같이 30으로 바뀔 것이다. 아울러 해당 node의 상위 node들에  
    기록된 이용 빈도 수치도 전부 30으로 갱신될 것이다.

![picture 10](/images/SDI_SKAS_10.png)

#### 검색어 삭제

- 혐오성이 짙거나 폭력적인 이유 등으로 부적절한 질의어들은 자동완성 결과에서 제거해야 한다. 이를 위한 좋은 방법은 아래 그림처럼  
  trie cache 앞에 filter layer를 두고 부적절한 질의어가 반환되지 않도록 하는 것이다. Filter layer를 두면 filter 규칙에 따라  
  검색 결과를 자유롭게 변경할 수 있다는 장점이 있다. 데이터베이스에서 해당 검색어를 물리적으로 삭제하는 것은 다음번 업데이트 cycle에  
  비동기적으로 진행하면 된다.

![picture 11](/images/SDI_SKAS_11.png)

### 저장소 규모 확장

- 자동완성된 검색어를 사용자에게 제공하는 시스템의 설계를 마쳤으니, trie의 크기가 한 서버에 넣기엔 너무 큰 경우에도 대응할 수 있도록  
  규모 확장성 문제를 해결해보자.

- 영어 소문자만 지원하면 되기에 간단하게는 첫 글자를 기준으로 sharding하는 방법을 생각해볼 수 있다. 아래 예시를 보자.

  - 검색어를 보관하기 위해 2대의 서버가 필요하다면 'a'부터 'm'까지 글자로 시작하는 검색어는 1번 서버에, 나머지는 2번 서버에 저장한다.
  - 3대의 서버가 필요하다면 'a'부터 'i'까지는 1번 서버에, 'i'부터 'r'까지는 2번 서버에, 그리고 나머지는 3번 서버에 저장한다.

- 이 방법을 쓰는 경우 사용 가능한 서버는 최대 26대로 제한되는데, 이는 영어 알파벳이 26개 있기 때문이다. 이 이상으로 서버 대수를 늘리려면  
  sharding을 계층적으로 해야 한다. 가령 검색어의 첫 번째 글자는 첫 번째 레벨의 sharding에 두고, 두 번째 글자는 두 번째 레벨의 sharding에  
  두는 것이다. 예를 들어 'a'로 시작하는 검색어를 4개의 서버에 나눠 보관하고 싶다 해보자. 그러면 'aa'부터 'ag'까지는 1번 서버,  
  'ah'부터 'an'까지는 2번 서버, 'ao'부터 'au'까지는 3번 서버, 그리고 나머지는 4번 서버에 보관하는 것이다.

- 얼핏 생각하기에 위 방법이 그럴싸해 보일 수 있지만, 'c'로 시작하는 단어가 'x'로 시작하는 단어보다 많다는 점을 감안하면 그렇지 않다.  
  즉 데이터를 각 서버에 균등하게 배분하기가 불가능하다는 것이다.

- 이 문제를 해결하기 위해 이 설계안은 과거 질의 데이터의 패턴을 분석해 sharding하는 아래 그림과 같은 기법을 제안한다.  
  이 그림에서 shard map manager(검색어 대응 shard 관리자)는 어떤 검색어가 어느 저장소 서버에 저장되는지에 대한 정보를 관리한다.  
  예를 들어 's'로 시작하는 검색어의 양이 'u', 'w', 'x', 'y', 'z'로 시작하는 검색어를 전부 합친 것과 비슷하다면 's'에 대한  
  shard 하나와 'u'부터 'z'까지의 검색어를 위한 shard 하나를 둬도 충분할 것이다.

![picture 12](/images/SDI_SKAS_12.png)

---

## 마무리

- 고려해볼 만한 점들을 더 보자.

- 비영어권 국가에서 사용하는 언어를 지원하려면(다국어 지원) trie에 unicode 데이터를 저장해야 한다.  
  Unicode는 문자 체계를 지원하는 표준 encoding 시스템이다.

- 국가별로 인기 검색어 순위가 다르다면 국가별로 다른 trie를 사용하도록 하면 된다. Trie를 CDN에 저장해 응답 속도를 높이는 방법도 고려해볼 수 있다.

- 실시간 검색어 자동완성 서비스를 구축하는 데에 적용해 볼만한 아이디어들은 아래와 같다.

  - Sharding을 통해 작업 대상 데이터의 양을 줄인다.
  - Ranking model을 바꿔 최근 검색어에 보다 높은 가중치를 부여한다.
  - 데이터가 stream 형태로 올 수 있다는 점을 고려한다.

---
