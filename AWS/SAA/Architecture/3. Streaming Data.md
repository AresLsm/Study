# Streaming Data

## Fundamentals of Stream Processing

### Batch Processing

- Data is collected, stored, and analayzed in chunks of a fixed size on a regular schedule.
- The schedule depends on the **frequency of data collection** and the **related value of the insight gained.**

> Value: At the center of stream processing.

### Addressing the Shortcomings of Batch Processing

- Some data are only valuable at a particular moment.

- Problems of Batch Processing

  - (1) Batch processing systems split data into time intervals that are consistent and evenly spaced,  
    which creates a steady workload that is predictable. While it is predictable, **it has no intelligence.**

  - (2) Batch processing systems are also designed to wait until a specific amount of data is accumulated before  
    processing starts. This leads to inconsistent time period in each batch of data.

### Stream Processing

- Stream Processing was created to address issues of latency, session boundaries, and inconsistent load.

- The term _streaming_ is used to describe information as it flows continuously without a beginning or end.

- Data sources for stream can be applications, networking devices, server log files, web activities,  
  location data and much more. All of these can be aggregated in real-time to respond and perform analysis  
  from a single source of truth.

- Stream processing is acting on, or reacting to data while it is in motion.  
  **Computation** happens in the moment data is produced or received.

- When receiving an event from the stream, a stream processing application _reacts_ to it. This reaction might be  
  to trigger an action, update an aggregate or similar statistic, or cache an event for future reference.

### Stream Application

- A stream application consists of three parts:
  - Producer: Collects events and transactions and put into the Data Stream.
  - Data Stream: Stores the data itself.
  - Consumer: Access the Data Streams, read the data and then act on it.

### Benefits of using Streaming Data

- When dealing with never-ending data

  - Best processed while it is in-flight
  - Batch processing is built around a **data-at-rest architecture**: before processing can begin, the collection  
    has to be stopped, and the data must be stored.
  - Subsequent batches of data bring with them the need to aggregate data across multiple batches.  
    In constrast, streaming architectures handle never-ending data streams naturally with grace.
  - Using streams, patterns can be detected, results inspected, and multiple streams can be examined simultaneously.

- When dealing with limited storage capacity

  - Sometimes, the volume of data is larger than the existing storage capacity.
  - Using streams, the raw data can be processed in real-time and then retain only the information and insight  
    that is useful.

- When dealing with time-series data

  - Stream processing naturally fits with time-series data and the detection of patterns over time.
  - For example, when trying to detect a sequence such as the length of a web session in a continous stream of data,  
    it would be difficult to do in batches.
  - Time series data, such as that produced by IoT sensors, is the most continuous type of data that can be streamed.
  - IoT devices are a natural fit into a streaming data architecture.

- Reactions in Real-Time

  - Almost no lag time in between when events happen, insights are derived, and actions are taken.
  - Actions and analytics are up-to-date and reflect data while it is still fresh, meaningful, and valuable.

- Decoupled Architectures improve operational efficiency

  - Streaming reduces the need for large and expensive shared databases: each stream processing application  
    maintains its own data and state, which is made simple by the stream processing framework.
  - Stream processing fits naturally inside a microservices architecture.

---
